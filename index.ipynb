{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T21:22:50.801786Z",
     "start_time": "2020-09-09T21:22:42.475800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T21:23:34.225231Z",
     "start_time": "2020-09-09T21:23:33.138489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T21:26:17.001776Z",
     "start_time": "2020-09-09T21:26:16.942737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(10000, random_state=123)\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df_sample['Product']\n",
    "X = df_sample['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T21:27:18.309883Z",
     "start_time": "2020-09-09T21:27:18.297876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T21:28:03.025626Z",
     "start_time": "2020-09-09T21:28:03.017623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T21:30:33.052324Z",
     "start_time": "2020-09-09T21:30:30.528389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary')\n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:08:32.754755Z",
     "start_time": "2020-09-09T22:08:32.613154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final))[:, :, 1]\n",
    "y_val_lb = to_categorical(lb.transform(y_val))[:, :, 1]\n",
    "y_test_lb = to_categorical(lb.transform(y_test))[:, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:11:18.822310Z",
     "start_time": "2020-09-09T22:11:18.780306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "baseline_model.add(layers.Dense(25, activation='relu'))\n",
    "baseline_model.add(layers.Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:13:37.595780Z",
     "start_time": "2020-09-09T22:13:37.563799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(loss='categorical_crossentropy', optimizer='sgd',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:20:05.079315Z",
     "start_time": "2020-09-09T22:19:30.467519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.9520 - acc: 0.1369 - val_loss: 1.9364 - val_acc: 0.1670\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.9316 - acc: 0.1709 - val_loss: 1.9225 - val_acc: 0.1800\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.9155 - acc: 0.1923 - val_loss: 1.9084 - val_acc: 0.1800\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.8982 - acc: 0.2041 - val_loss: 1.8916 - val_acc: 0.1990\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.8775 - acc: 0.2281 - val_loss: 1.8708 - val_acc: 0.2280\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.8528 - acc: 0.2501 - val_loss: 1.8468 - val_acc: 0.2440\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.8246 - acc: 0.2707 - val_loss: 1.8193 - val_acc: 0.2660\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.7924 - acc: 0.2943 - val_loss: 1.7881 - val_acc: 0.2920\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.7564 - acc: 0.3145 - val_loss: 1.7532 - val_acc: 0.3020\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.7172 - acc: 0.3313 - val_loss: 1.7154 - val_acc: 0.3220\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.6759 - acc: 0.3513 - val_loss: 1.6744 - val_acc: 0.3510\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.6330 - acc: 0.3743 - val_loss: 1.6320 - val_acc: 0.3730\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.5895 - acc: 0.3987 - val_loss: 1.5888 - val_acc: 0.3960\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.5455 - acc: 0.4223 - val_loss: 1.5433 - val_acc: 0.4250\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.5003 - acc: 0.4487 - val_loss: 1.4982 - val_acc: 0.4710\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.4554 - acc: 0.4795 - val_loss: 1.4531 - val_acc: 0.4810\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.4095 - acc: 0.5039 - val_loss: 1.4077 - val_acc: 0.5100\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.3647 - acc: 0.5332 - val_loss: 1.3632 - val_acc: 0.5430\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.3205 - acc: 0.5659 - val_loss: 1.3197 - val_acc: 0.5580\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.2772 - acc: 0.5897 - val_loss: 1.2772 - val_acc: 0.5900\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.2353 - acc: 0.6136 - val_loss: 1.2382 - val_acc: 0.6070\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.1953 - acc: 0.6297 - val_loss: 1.1998 - val_acc: 0.6170\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.1564 - acc: 0.6481 - val_loss: 1.1600 - val_acc: 0.6400\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.1190 - acc: 0.6613 - val_loss: 1.1254 - val_acc: 0.6470\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.0838 - acc: 0.6713 - val_loss: 1.0930 - val_acc: 0.6580\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.0500 - acc: 0.6821 - val_loss: 1.0593 - val_acc: 0.6640\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.0190 - acc: 0.6900 - val_loss: 1.0312 - val_acc: 0.6640\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.9893 - acc: 0.7001 - val_loss: 1.0043 - val_acc: 0.6790\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.9615 - acc: 0.7063 - val_loss: 0.9789 - val_acc: 0.6820\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.9361 - acc: 0.7127 - val_loss: 0.9566 - val_acc: 0.6860\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.9118 - acc: 0.7185 - val_loss: 0.9327 - val_acc: 0.6940\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8893 - acc: 0.7243 - val_loss: 0.9141 - val_acc: 0.6930\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.8680 - acc: 0.7267 - val_loss: 0.8967 - val_acc: 0.6960\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.8483 - acc: 0.7335 - val_loss: 0.8795 - val_acc: 0.6990\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.8296 - acc: 0.7387 - val_loss: 0.8699 - val_acc: 0.6950\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.8132 - acc: 0.7428 - val_loss: 0.8542 - val_acc: 0.7030\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.7966 - acc: 0.7440 - val_loss: 0.8369 - val_acc: 0.7070\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7810 - acc: 0.7485 - val_loss: 0.8255 - val_acc: 0.7100\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7672 - acc: 0.7529 - val_loss: 0.8120 - val_acc: 0.7180\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7529 - acc: 0.7569 - val_loss: 0.8067 - val_acc: 0.7170\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7407 - acc: 0.7595 - val_loss: 0.7938 - val_acc: 0.7190\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7283 - acc: 0.7613 - val_loss: 0.7866 - val_acc: 0.7170\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7168 - acc: 0.7689 - val_loss: 0.7753 - val_acc: 0.7240\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7056 - acc: 0.7676 - val_loss: 0.7677 - val_acc: 0.7270\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.6959 - acc: 0.7705 - val_loss: 0.7600 - val_acc: 0.7250\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6857 - acc: 0.7761 - val_loss: 0.7514 - val_acc: 0.7260\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.6766 - acc: 0.7777 - val_loss: 0.7480 - val_acc: 0.7200\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6674 - acc: 0.7797 - val_loss: 0.7423 - val_acc: 0.7220\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.6589 - acc: 0.7832 - val_loss: 0.7358 - val_acc: 0.7230\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6505 - acc: 0.7833 - val_loss: 0.7298 - val_acc: 0.7220\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6423 - acc: 0.7880 - val_loss: 0.7289 - val_acc: 0.7280\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6347 - acc: 0.7897 - val_loss: 0.7204 - val_acc: 0.7240\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6274 - acc: 0.7919 - val_loss: 0.7227 - val_acc: 0.7230\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6206 - acc: 0.7948 - val_loss: 0.7145 - val_acc: 0.7290\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.6133 - acc: 0.7957 - val_loss: 0.7108 - val_acc: 0.7270\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6068 - acc: 0.8003 - val_loss: 0.7115 - val_acc: 0.7240\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.6003 - acc: 0.8019 - val_loss: 0.7036 - val_acc: 0.7310\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5937 - acc: 0.8029 - val_loss: 0.7060 - val_acc: 0.7350\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5878 - acc: 0.8036 - val_loss: 0.7043 - val_acc: 0.7260\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5815 - acc: 0.8065 - val_loss: 0.6934 - val_acc: 0.7370\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5756 - acc: 0.8071 - val_loss: 0.6967 - val_acc: 0.7360\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.5699 - acc: 0.8107 - val_loss: 0.6893 - val_acc: 0.7310\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.5645 - acc: 0.8115 - val_loss: 0.6873 - val_acc: 0.7280\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.5590 - acc: 0.8143 - val_loss: 0.6870 - val_acc: 0.7310\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5535 - acc: 0.8157 - val_loss: 0.6825 - val_acc: 0.7440\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5483 - acc: 0.8171 - val_loss: 0.6814 - val_acc: 0.7320\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.5430 - acc: 0.8187 - val_loss: 0.6800 - val_acc: 0.7340\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5379 - acc: 0.8197 - val_loss: 0.6823 - val_acc: 0.7360\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5336 - acc: 0.8209 - val_loss: 0.6724 - val_acc: 0.7390\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5283 - acc: 0.8229 - val_loss: 0.6739 - val_acc: 0.7330\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5240 - acc: 0.8251 - val_loss: 0.6717 - val_acc: 0.7440\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.5191 - acc: 0.8248 - val_loss: 0.6732 - val_acc: 0.7330\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5146 - acc: 0.8307 - val_loss: 0.6684 - val_acc: 0.7380\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5098 - acc: 0.8284 - val_loss: 0.6672 - val_acc: 0.7450\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5058 - acc: 0.8309 - val_loss: 0.6650 - val_acc: 0.7390\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5010 - acc: 0.8332 - val_loss: 0.6649 - val_acc: 0.7410\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.4970 - acc: 0.8327 - val_loss: 0.6672 - val_acc: 0.7400\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4927 - acc: 0.8347 - val_loss: 0.6661 - val_acc: 0.7360\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4885 - acc: 0.8377 - val_loss: 0.6708 - val_acc: 0.7430\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4845 - acc: 0.8403 - val_loss: 0.6611 - val_acc: 0.7410\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4799 - acc: 0.8431 - val_loss: 0.6614 - val_acc: 0.7470\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.4762 - acc: 0.8424 - val_loss: 0.6596 - val_acc: 0.7420\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4722 - acc: 0.8444 - val_loss: 0.6578 - val_acc: 0.7450\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4691 - acc: 0.8453 - val_loss: 0.6591 - val_acc: 0.7450\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4645 - acc: 0.8475 - val_loss: 0.6593 - val_acc: 0.7410\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4607 - acc: 0.8489 - val_loss: 0.6605 - val_acc: 0.7410\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.4566 - acc: 0.8523 - val_loss: 0.6575 - val_acc: 0.7490\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.4530 - acc: 0.8521 - val_loss: 0.6569 - val_acc: 0.7450\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4498 - acc: 0.8521 - val_loss: 0.6649 - val_acc: 0.7400\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4460 - acc: 0.8555 - val_loss: 0.6576 - val_acc: 0.7460\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4423 - acc: 0.8551 - val_loss: 0.6578 - val_acc: 0.7450\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4382 - acc: 0.8585 - val_loss: 0.6646 - val_acc: 0.7400\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.4348 - acc: 0.8577 - val_loss: 0.6650 - val_acc: 0.7390\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4319 - acc: 0.8599 - val_loss: 0.6583 - val_acc: 0.7450\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4279 - acc: 0.8613 - val_loss: 0.6564 - val_acc: 0.7500\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4249 - acc: 0.8635 - val_loss: 0.6564 - val_acc: 0.7530\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4208 - acc: 0.8644 - val_loss: 0.6597 - val_acc: 0.7530\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.4182 - acc: 0.8663 - val_loss: 0.6539 - val_acc: 0.7510\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4148 - acc: 0.8683 - val_loss: 0.6565 - val_acc: 0.7490\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4115 - acc: 0.8676 - val_loss: 0.6558 - val_acc: 0.7470\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4080 - acc: 0.8691 - val_loss: 0.6542 - val_acc: 0.7490\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4047 - acc: 0.8719 - val_loss: 0.6612 - val_acc: 0.7470\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4016 - acc: 0.8731 - val_loss: 0.6579 - val_acc: 0.7430\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3985 - acc: 0.8743 - val_loss: 0.6583 - val_acc: 0.7510\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3957 - acc: 0.8745 - val_loss: 0.6559 - val_acc: 0.7500\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3928 - acc: 0.8768 - val_loss: 0.6645 - val_acc: 0.7470\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3896 - acc: 0.8759 - val_loss: 0.6551 - val_acc: 0.7510\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.3865 - acc: 0.8785 - val_loss: 0.6605 - val_acc: 0.7500\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3834 - acc: 0.8791 - val_loss: 0.6592 - val_acc: 0.7500\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3805 - acc: 0.8815 - val_loss: 0.6579 - val_acc: 0.7500\n",
      "Epoch 111/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3777 - acc: 0.8824 - val_loss: 0.6580 - val_acc: 0.7520\n",
      "Epoch 112/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3748 - acc: 0.8837 - val_loss: 0.6601 - val_acc: 0.7520\n",
      "Epoch 113/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3716 - acc: 0.8837 - val_loss: 0.6593 - val_acc: 0.7520\n",
      "Epoch 114/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3688 - acc: 0.8861 - val_loss: 0.6608 - val_acc: 0.7540\n",
      "Epoch 115/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3665 - acc: 0.8867 - val_loss: 0.6753 - val_acc: 0.7380\n",
      "Epoch 116/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3636 - acc: 0.8871 - val_loss: 0.6615 - val_acc: 0.7520\n",
      "Epoch 117/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.3603 - acc: 0.8877 - val_loss: 0.6657 - val_acc: 0.7480\n",
      "Epoch 118/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3575 - acc: 0.8915 - val_loss: 0.6682 - val_acc: 0.7460\n",
      "Epoch 119/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3552 - acc: 0.8907 - val_loss: 0.6681 - val_acc: 0.7540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.3524 - acc: 0.8912 - val_loss: 0.6612 - val_acc: 0.7530\n",
      "Epoch 121/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3497 - acc: 0.8933 - val_loss: 0.6652 - val_acc: 0.7530\n",
      "Epoch 122/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3466 - acc: 0.8932 - val_loss: 0.6676 - val_acc: 0.7520\n",
      "Epoch 123/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.3446 - acc: 0.8935 - val_loss: 0.6674 - val_acc: 0.7530\n",
      "Epoch 124/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3418 - acc: 0.8953 - val_loss: 0.6724 - val_acc: 0.7460\n",
      "Epoch 125/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3393 - acc: 0.8977 - val_loss: 0.6709 - val_acc: 0.7530\n",
      "Epoch 126/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.3368 - acc: 0.8976 - val_loss: 0.6644 - val_acc: 0.7530\n",
      "Epoch 127/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3340 - acc: 0.8993 - val_loss: 0.6663 - val_acc: 0.7510\n",
      "Epoch 128/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3317 - acc: 0.8993 - val_loss: 0.6711 - val_acc: 0.7530\n",
      "Epoch 129/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3295 - acc: 0.9015 - val_loss: 0.6672 - val_acc: 0.7530\n",
      "Epoch 130/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3269 - acc: 0.9021 - val_loss: 0.6691 - val_acc: 0.7530\n",
      "Epoch 131/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3241 - acc: 0.9036 - val_loss: 0.6725 - val_acc: 0.7540\n",
      "Epoch 132/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3218 - acc: 0.9028 - val_loss: 0.6789 - val_acc: 0.7500\n",
      "Epoch 133/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3196 - acc: 0.9048 - val_loss: 0.6698 - val_acc: 0.7570\n",
      "Epoch 134/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3170 - acc: 0.9047 - val_loss: 0.6865 - val_acc: 0.7500\n",
      "Epoch 135/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3148 - acc: 0.9061 - val_loss: 0.6740 - val_acc: 0.7530\n",
      "Epoch 136/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3126 - acc: 0.9057 - val_loss: 0.6744 - val_acc: 0.7550\n",
      "Epoch 137/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3103 - acc: 0.9063 - val_loss: 0.6733 - val_acc: 0.7570\n",
      "Epoch 138/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3077 - acc: 0.9089 - val_loss: 0.6763 - val_acc: 0.7560\n",
      "Epoch 139/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3052 - acc: 0.9104 - val_loss: 0.6805 - val_acc: 0.7550\n",
      "Epoch 140/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.3032 - acc: 0.9105 - val_loss: 0.6770 - val_acc: 0.7550\n",
      "Epoch 141/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.3012 - acc: 0.9104 - val_loss: 0.6788 - val_acc: 0.7530\n",
      "Epoch 142/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.2989 - acc: 0.9127 - val_loss: 0.6775 - val_acc: 0.7570\n",
      "Epoch 143/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.2966 - acc: 0.9132 - val_loss: 0.6816 - val_acc: 0.7550\n",
      "Epoch 144/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.2946 - acc: 0.9145 - val_loss: 0.6882 - val_acc: 0.7540\n",
      "Epoch 145/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.2923 - acc: 0.9156 - val_loss: 0.6817 - val_acc: 0.7550\n",
      "Epoch 146/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.2903 - acc: 0.9163 - val_loss: 0.6930 - val_acc: 0.7470\n",
      "Epoch 147/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.2886 - acc: 0.9165 - val_loss: 0.6820 - val_acc: 0.7530\n",
      "Epoch 148/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2867 - acc: 0.9189 - val_loss: 0.6831 - val_acc: 0.7510\n",
      "Epoch 149/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.2843 - acc: 0.9179 - val_loss: 0.6912 - val_acc: 0.7520\n",
      "Epoch 150/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.2821 - acc: 0.9197 - val_loss: 0.6851 - val_acc: 0.7510\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(X_train_tokens, y_train_lb, \n",
    "                                        epochs=150, batch_size=256,\n",
    "                                       validation_data=(X_val_tokens, \n",
    "                                                        y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:20:54.592130Z",
     "start_time": "2020-09-09T22:20:54.587133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "baseline_model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:22:11.415863Z",
     "start_time": "2020-09-09T22:22:11.188994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 29us/step\n",
      "----------\n",
      "Training Loss: 0.279 \n",
      "Training Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:22:58.884873Z",
     "start_time": "2020-09-09T22:22:58.827893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 35us/step\n",
      "----------\n",
      "Test Loss: 0.614 \n",
      "Test Accuracy: 0.787\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:33:36.896114Z",
     "start_time": "2020-09-09T22:33:36.722189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "loss_values = baseline_model_val_dict['loss']\n",
    "val_loss_values = baseline_model_val_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "ax.plot(epochs, loss_values, label='Training Loss')\n",
    "ax.plot(epochs, val_loss_values, label='Validation Loss')\n",
    "ax.set_title('Training v. Validation Loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:36:10.087311Z",
     "start_time": "2020-09-09T22:36:09.905416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAHwCAYAAACG+PhNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi41LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvSM8oowAAIABJREFUeJzs3Xd8VfX9x/HX997svRkJSdg7rMgQlFURrYMlAmIdpai10mrtr25bf7Zaa/05Wm3digxBK6KIGweg7CV7JWSQvcdN7vj+/vjehCQkECAhg8/z8cgD7jnnnvM9Jwm87/d8zvertNYIIYQQQgghzo6lpRsghBBCCCFEWyaBWgghhBBCiHMggVoIIYQQQohzIIFaCCGEEEKIcyCBWgghhBBCiHMggVoIIYQQQohzIIFaCNGmKaWsSqkSpVRsU27bViilPJRSWikV7379qlLqgcZsexbHukkptfps2yqEEO2VknGohRDnk1KqpMZLP6ACcLpf36a1XnT+W9VylFKvYf4tvrXO8mHAOqCj1rrgFO/3AOxAV6110mmOdSbb9gAOaq1VY86jKVQdE3hBa73gfB1XCCHOlfRQCyHOK611QNUXcAy4usayk8K0OwS2Z28CM5RSvnWW3wh8eKow3Q7dBOQBs5VSnufzwBfAz5kQohlJoBZCtCpKqceVUu8qpZYopYqBuUqpUUqpH5VSBUqp40qp56sCVz0lD++4169WShUrpX5QSnU9023d669QSh1QShUqpV5QSq1TSt1cT5u7KKXKlFLBNZZdpJTKakRQWwtkA1NrvNcDmA285X7d4PnX05Z3lFJ/qvH6PqVUhlIqDRNYa257jVJqu/vcjymlHq6x+jv3NiXur4uUUvOUUt/UeP8YpdRm9/XZqJQaUWPdWqXUn5VS6937/1QpFdbQRVBKKcyHiPsBBfy8zvqBSqkvlVJ57vP5n6prpZR6WCl1WClV5G5PZ6VUD6WUrrOPtVXfP/e5fOe+lnnAQ0qpnkqpNUqpXKVUjlJqYZ3vaZxSaoVSKtu9/jmllI/7+9K3xnad3D8P4Q2drxCifZFALYRojaYCi4Fg4F3AAfwWiABGA5OB207x/jnAw0AYphf8f890W6VUFLAM+IP7uEeB4fXtQGudAmwGptXZ7zKtteMUx0aburu3gV/UWHw5oIHP3a/P9Pxxn8NV7vdNAHq591tTCTAXc52vBn7rfg/Ape72Vd092FRn3xHAKuAfQDjwPPCJUiq0xmZzMCG+A+AP3HOK5o5zb/cusJwa18Mdar8EPgI6uc/lG/fqPwAzMNckBJgH2E5xnJouBvYCkcDfMEH+cfcx+gHdMD8bVR9yVgGHgHigC+b7a8P8nMytc96faa1zG9kOIUQbJ4FaCNEardVaf6S1dmmty7XWm7TWG7TWDq31EeBlYOwp3v+e1nqz1toOLAIGn8W2VwHbtdYfutf9H5Bziv0sxvQqo5SyANe7lzXG28BEpVQn9+tfAIuqwvhZnH+VmcBrWus9WutS4E81V2qtv9Za/+S+zjuApY3cL5gAvltrvcTdrneAI9TuWX5Na31Qa12GCcmn+j7cBKzSWhdirtvPa/TwXgOkaK2f01pXaK2LtNYb3evmAQ+4j+PSWm/XWuc18hyOaa1f0lo73T9nB7TWX2mtK7XWWZjvedX1GIX5QPNHrXWpe/t17nVvAXPcvexgetoXNrINQoh2QAK1EKI1Sqn5QinVRym1yn2rvwh4DBNuGpJR4+9lQMBZbNu5ZjvcPcmpp9jPcuASpVQHYDxg01qvP8X21bTWR4H1wA1KqSBMgHy7av1ZnH+VWucAJNdc6S4l+cZdwlCICaeN2W/VvpPrLEsGomu8btT3QSnlD0zHfKABUwZzHPcHFExv8KEG2tEFONzINtdV9+eso1JqmVIqzX2d3+TE9egCJGmtnXX2gTtYO4AxSqkBQCymN1sIcYGQQC2EaI3qDj/0H+AnoIfWOgh4BHN7vjkdB2KqXrh7H6Mb2th9e/9r4DrMLf8lZ3i8tzA909cB+909xlXO9vyPY4JglbrDBS4F3ge6aK2DgVdr7Pd0Q0ClA3F1lsUCaY1oV13TMWH7ZaVUhrvdHTlR9pECdG/gvQ2tKwVQSvnVWNaxzjZ1z/FvmFFnBrqv882cuB4pQJxSytpAO97GlH3ciCkFqWhgOyFEOySBWgjRFgQChUCp++Gv09YPN4GPgaFKqavd9bO/xdTanspiTOnCNBpf7lFlOSYYPoz7YcQazvb8lwG3unu4/YFH69lvntbappQaCcyqsS4L0Eqpbg3s+2Ogv1LqeveDgXOAHsAnjWxbTTcBrwADMWUhgzE13Inu810JxCqlfqOU8lJKBSmlqurZXwUeV0p1V8Zg98OPGe6vucqMPz6fkz8A1BWICeKFSqkuwL011v0A5AJ/VUr5KaV8lVKja6xfiKnlnkONuwtCiAuDBGohRFvwe0zoKsb01r7b3AfUWmdi6qCfwQSp7sA2TA9mQ1ZgHmY7prXeXbVQKTVOKXXK4e+01sXAB5he8Lph/KzOX2v9EfAv4FvgAPBFnU3uAJ5QZjSVBzABvGZ7ngA2uEexSKyz72xMacofMdfnbuCqM6hfBkCZSXbGAc9qrTNqfG3EPIh4k7uu+jJMT3aW+1yqapv/jrnuXwFFmPpyH3eJzq/c55WDCfsbTtOcRzEPnhZiQvz7Nc7Xgamr74vprT6GCdBV65OAXUBlY0t9hBDth0zsIoQQjeC+1Z8OzNBaf9/S7RGtj1LqbeCI1vpPLd0WIcT5JQPZCyFEA5RSkzG3+m2Y8ZEdwMZTvklckNylMddiylaEEBcYKfkQQoiGjcEMBZeDGed4ijxsJupSSj0B7AD+qrU+1tLtEUKcf1LyIYQQQgghxDmQHmohhBBCCCHOgQRqIYQQQgghzkGbeygxIiJCx8fHt3QzhBBCCCFEO7dly5YcrfXp5iBoe4E6Pj6ezZs3t3QzhBBCCCFEO6eUSm7MdlLyIYQQQgghxDmQQC2EEEIIIcQ5kEAthBBCCCHEOWhzNdT1sdvtpKamYrPZWropohXx8fEhJiYGT0/Plm6KEEIIIdqxdhGoU1NTCQwMJD4+HqVUSzdHtAJaa3Jzc0lNTaVr164t3RwhhBBCtGPtouTDZrMRHh4uYVpUU0oRHh4udy2EEEII0ezaRaAGJEyLk8jPhBBCCCHOh3YTqFtSbm4ugwcPZvDgwXTs2JHo6Ojq15WVlY3axy233ML+/ftPuc2//vUvFi1a1BRNBiAzMxMPDw9ee+21JtunEEIIIcSFRmmtW7oNZyQxMVHXndhl79699O3bt4VaVNuf/vQnAgICuPfee2st11qjtcZiaT2fYZ5//nmWL1+Ot7c3X375ZbMdx+Fw4OHRMuX6relnQwghhBBti1Jqi9Y68XTbtZ501w4dOnSIAQMGcPvttzN06FCOHz/O/PnzSUxMpH///jz22GPV244ZM4bt27fjcDgICQnhvvvuY9CgQYwaNYqsrCwAHnroIZ599tnq7e+77z6GDx9O7969Wb9+PQClpaVMnz6dQYMGMXv2bBITE9m+fXu97VuyZAnPPvssR44cISMjo3r5qlWrGDp0KIMGDWLSpEkAFBcXc9NNNzFw4EASEhJYsWJFdVurLF26lHnz5gEwd+5cfv/73zN+/HgeeOABfvzxR0aNGsWQIUMYPXo0Bw8eBEzYvvvuuxkwYAAJCQm8+OKLfPbZZ1x33XXV+129ejUzZ8485++HEEIIIURzaBejfNT05492sye9qEn32a9zEI9e3f+s3rtnzx7eeOMN/v3vfwPw5JNPEhYWhsPhYPz48cyYMYN+/frVek9hYSFjx47lySef5J577uH111/nvvvuO2nfWms2btzIypUreeyxx/j000954YUX6NixI++//z47duxg6NCh9bYrKSmJ/Px8hg0bxowZM1i2bBkLFiwgIyODO+64g++//564uDjy8vIA0/MeGRnJrl270FpTUFBw2nM/fPgwX331FRaLhcLCQtauXYvVauXTTz/loYce4t133+Wll14iPT2dHTt2YLVaycvLIyQkhAULFpCbm0t4eDhvvPEGt9xyy5leeiGEEEKI80J6qJtZ9+7dueiii6pfL1myhKFDhzJ06FD27t3Lnj17TnqPr68vV1xxBQDDhg0jKSmp3n1PmzbtpG3Wrl3LrFmzABg0aBD9+9f/QWDJkiVcf/31AMyaNYslS5YA8MMPPzB+/Hji4uIACAsLA+DLL7/kzjvvBMzDfqGhoac99+uuu666xKWgoIBp06YxYMAA7r33Xnbv3l2939tvvx2r1Vp9PIvFwpw5c1i8eDF5eXls2bKluqdcCCGEEKK1aXc91Gfbk9xc/P39q/9+8OBBnnvuOTZu3EhISAhz586td1g3Ly+v6r9brVYcDke9+/b29j5pm8bWxC9ZsoTc3FzeeustANLT0zl69Cha63pHx6hvucViqXW8uudS89wffPBBLr/8cn79619z6NAhJk+e3OB+AW699VamT58OwPXXX18duIUQQgghWhvpoT6PioqKCAwMJCgoiOPHj/PZZ581+THGjBnDsmXLANi1a1e9PeB79uzB6XSSlpZGUlISSUlJ/OEPf2Dp0qWMHj2ar7/+muTkZIDqko9Jkybxz3/+EzAhOD8/H4vFQmhoKAcPHsTlcvHBBx802K7CwkKio6MBePPNN6uXT5o0iZdeegmn01nreF26dCEiIoInn3ySm2+++dwuihBCCCFEM5JAfR4NHTqUfv36MWDAAH71q18xevToJj/GXXfdRVpaGgkJCfzjH/9gwIABBAcH19pm8eLFTJ06tday6dOns3jxYjp06MBLL73Etddey6BBg7jhhhsAePTRR8nMzGTAgAEMHjyY77//HoC//e1vTJ48mYkTJxITE9Ngu/74xz/yhz/84aRzvu222+jYsSMJCQkMGjSo+sMAwJw5c+jatSu9evU6p2sihBBCCNGcZNi8dsbhcOBwOPDx8eHgwYNMmjSJgwcPttiwdefi9ttvZ9SoUdx0001nvQ/52RBCCCHE2WrssHltL2WJUyopKWHixIk4HA601vznP/9pk2F68ODBhIaG8vzzz7d0U4QQQgjRQrTWZBVX0CHIp6WbckptL2mJUwoJCWHLli0t3Yxz1tDY2UIIIYRo+5wuzfaUfL7am0VuSSVdwnzpEuZHbJgfLq3ZkpzP5qR8tiTnU253svPRSXhYW2+lsgRqIYQQQgjRZMorneSWVpBXWkluaSWlFQ4q7C4qHC5sdic/pRWyZn8W+WV2PCyKED9PckoqT9pPfLgf43pHkRgfisOl8WjFA35JoBZCCCGEEGckt6SCg1klHMwq4VhuKcfyyjiWV05KXhklFfUP91sl1M+T8b2jmNA3ikt6RhLs60lZpYPU/HKO5Zbh0pohsaFEBnqfp7M5dxKohRBCCCFELQ6ni+0pBWw4mkdOSQVF5Q4Ky+0UlFVyJKeUvNITPcreHhZiw/zoEubH8PhQOgT7EO7vRZi/N2H+XgT6eODtYcHH04q3h4VAH0+sltpzUPh5edCrQyC9OgSe71NtEhKohRBCCCHaudIKB/szi0nJK8Pu1DhdLuxOjUtrrBaFh0XhYbFQZney/lAOaw/lUGwzPc0B3h4E+3oS5OtJiK8nl/fvQI+oQHpGBdAjKoBOwT71TtJ2IZFA3QTGjRvH/fffz+WXX1697Nlnn+XAgQO8+OKLDb4vICCAkpIS0tPTWbBgAe+99169+3766adJTGx4xJZnn32W+fPn4+fnB8CVV17J4sWLCQkJOYezOmHQoEH069evenpyIYQQQrRuWUU2PtudwbpDuezLKCI5r4zGjpTcMciHKwd04tJekYzpEUGwn2fzNrYdkEDdBGbPns3SpUtrBeqlS5fy97//vVHv79y5c71hurGeffZZ5s6dWx2oP/nkk7PeV1179+7F5XLx3XffUVpaWms68abkcDja5PB+QgghxPmgtSY1v5xyuxM/LysB3h74eXmg0RSW2ykqt1NYbmdXaiGf7MpgU3IeWkNsmB8DooOYNjSGvp2C6Brhh7eH1fRKWxUWpXC6NA6XxunUKAUxob4XfI/zmWrWBKOUmgw8B1iBV7XWT9ZZHwe8DkQCecBcrXVqc7apOcyYMYOHHnqIiooKvL29SUpKIj09nTFjxlBSUsK1115Lfn4+drudxx9/nGuvvbbW+5OSkrjqqqv46aefKC8v55ZbbmHPnj307duX8vLy6u3uuOMONm3aRHl5OTNmzODPf/4zzz//POnp6YwfP56IiAjWrFlDfHw8mzdvJiIigmeeeYbXX38dgHnz5vG73/2OpKQkrrjiCsaMGcP69euJjo7mww8/xNfX96RzW7x4MTfeeCN79+5l5cqVzJ49G4BDhw5x++23k52djdVqZfny5XTv3p2nnnqKhQsXYrFYuOKKK3jyySdr9bLn5OSQmJhIUlISb775JqtWrcJms1FaWsrKlSsbvFZvv/02Tz/9NEopEhISePHFF0lISODAgQN4enpSVFREQkICBw8exNNTPkkLIYRoOyodLnamFrA5OZ/SCgceFkt12E0vKGfv8SL2ZxRTfJqH/ar07hDI7yb24sqBHenZRmuS25pmC9RKKSvwL+AyIBXYpJRaqbXeU2Ozp4G3tdZvKaUmAE8AN57TgVffBxm7zmkXJ+k4EK54ssHV4eHhDB8+nE8//ZRrr72WpUuXcv3116OUwsfHhw8++ICgoCBycnIYOXIk11xzTYOf/F566SX8/PzYuXMnO3fuZOjQodXr/vKXvxAWFobT6WTixIns3LmTBQsW8Mwzz7BmzRoiIiJq7WvLli288cYbbNiwAa01I0aMYOzYsYSGhnLw4EGWLFnCK6+8wsyZM3n//feZO3fuSe159913+eKLL9i/fz///Oc/qwP1DTfcwH333cfUqVOx2Wy4XC5Wr17NihUr2LBhA35+fuTl5Z320v7www/s3LmTsLAwHA5Hvddqz549/OUvf2HdunVERESQl5dHYGAg48aNY9WqVUyZMoWlS5cyffp0CdNCCCFanN3pIr+skqyiCg5kFrP3eBH7Moo5nFWCv7cHUUHeRAX6EOrnxf7MIrYk52OzuwCwKHDVKM0I9PagT6dApgyJpm+nIIJ9PSmtcFBS4aCs0gTsqvrmYF9P4sL96RrRPHeTRcOas4d6OHBIa30EQCm1FLgWqBmo+wF3u/++BljRjO1pVlVlH1WBuqpXWGvNAw88wHfffYfFYiEtLY3MzEw6duxY736+++47FixYAEBCQgIJCQnV65YtW8bLL7+Mw+Hg+PHj7Nmzp9b6utauXcvUqVOryzSmTZvG999/zzXXXEPXrl0ZPHgwAMOGDSMpKemk92/atInIyEji4uKIiYnh1ltvJT8/Hw8PD9LS0pg6dSoAPj5m9qIvv/ySW265pbr0JCws7LTX7bLLLqverqFr9fXXXzNjxozqDwxV28+bN4+nnnqKKVOm8MYbb/DKK6+c9nhCCCFEU8oqtrH+UC7rDuWwLaWA7OIKCsvttbbx8rDQq0MAI7qFU17pJLPYxsajeeSWVhAf7s+si2IZ2S2M4V3DCfP3wuUuwXC4XPh6WqX8og1ozkAdDaTUeJ0KjKizzQ5gOqYsZCoQqJQK11rnnvVRT9GT3JymTJnCPffcw9atWykvL6/uWV60aBHZ2dls2bIFT09P4uPjsdlsp9xXfb84R48e5emnn2bTpk2EhoZy8803n3Y/+hRPH3h7nxjb0Wq11iotqbJkyRL27dtHfHw8AEVFRbz//vvMnDmzwePV13YPDw9cLvPJu26ba9ZkN3StGtrv6NGjSUpK4ttvv8XpdDJgwIAGz1cIIYQ4Uw6ni/2ZxexIKWR7Sj5JOWVoTvzfml9m51BWCWB6iS+KD+Pi7iYUh/t7ERHgTc8OAcSH+5/RLH8Wi8LLovCi9c4MKGprzkBd38epugnvXuCfSqmbge+ANOCkAiGl1HxgPkBsbGzTtrKJBAQEMG7cOG699dbqsgiAwsJCoqKi8PT0ZM2aNSQnJ59yP5deeimLFi1i/Pjx/PTTT+zcuRMwYdbf35/g4GAyMzNZvXo148aNAyAwMJDi4uKTSj4uvfRSbr75Zu677z601nzwwQcsXLiwUefjcrlYvnw5O3fuJDo6GoA1a9bw+OOPM2/ePGJiYlixYgVTpkyhoqICp9PJpEmTeOyxx5gzZ051yUdYWBjx8fFs2bKF4cOHn/Lhy4au1cSJE5k6dSp333034eHh1fsF+MUvfsHs2bN5+OGHG3VeQgghRBWXS7MjtYCv92Xx1d4sknNLsVoUnlYLVouiyGavLsUI9fOkZ4dAPC0nQm5cmB/Th8YwpkcE/ToHnTS2srhwNGegTgW61HgdA6TX3EBrnQ5MA1BKBQDTtdaFdXektX4ZeBkgMTGxkYO+nH+zZ89m2rRpLF26tHrZDTfcwNVXX01iYiKDBw+mT58+p9zHHXfcwS233EJCQgKDBw9m+PDhgBm6bsiQIfTv359u3boxevTo6vfMnz+fK664gk6dOrFmzZrq5UOHDuXmm2+u3se8efMYMmRIveUddX333XdER0dXh2kwAX3Pnj0cP36chQsXctttt/HII4/g6enJ8uXLmTx5Mtu3bycxMREvLy+uvPJK/vrXv3Lvvfcyc+ZMFi5cyIQJExo8ZkPXqn///jz44IOMHTsWq9XKkCFDePPNN6vf89BDD9X6ECOEEELUx+nSHMgsZnNyPpuT8lh3KIeckkosChLjwph5URe0BofLhcOp8fPyYFCXYAZ3CSE2zE9KL0SD1KnKAs5px0p5AAeAiZie503AHK317hrbRAB5WmuXUuovgFNr/cip9puYmKg3b95ca9nevXvp27dvU5+CaAPee+89PvzwwwZ73uVnQwgh2i+tNYezS1h7MIcNR/MoqXBU9y57WBQOl6bC4cJmd1Jhd3Iku7R6pIyoQG9GdgtnYt8oxvaKJMTPq4XPRrRGSqktWuuGJwNxa7Yeaq21Qyn1G+AzzLB5r2utdyulHgM2a61XAuOAJ5RSGlPycWdztUe0P3fddRerV69u0nG3hRBCtCyb3cn7W1P5aEc6Ad4eRAb6EBXoTUSAFza7y4y5bLOTW1LJ5uQ8MosqADN2ckSAd/WYyg6nCw+rBW8P8xXs58U1g4NJjA8lMS5MxloWTapZx6HWWn8CfFJn2SM1/v4ecPYzmogL2gsvvNDSTRBCCNFECsoqeefHZN5cn0ROSSU9owIoKLOz7VgBuaWV1dspBUE+noT4mYcAx/SIYHSPCLqE+bVg68WFTqamE0IIIUSTcro0GUU2CsvM7H01Z/Kr76uo3E56YTk2u4uxvSK5fWx3RnYLq+5BrnS4KCirxMfLSoCXBxZ5+E+0Mu0mUDc0tJq4cDXX8wFCCCFOVlhu57sD2Xy9L4tv9meRX2avdzuLonoSkqqv6FBfxvaOZGZiF/p2CjrpPV4eFqKCfJr7FIQ4a+0iUPv4+JCbm0t4eLiEagGYMJ2bm1s96YwQQoizU1LhIL2gnCPZpRzKKuZAZgkHs0ooLDtRhqGBrOIKnC5NqJ8n43tHkRgfRpi/50nhOcDbQ/6vFu1OuwjUMTExpKamkp2d3dJNEa2Ij48PMTExLd0MIYRoM7KLK1iz3/QwH8kuJa2gnGJb7ekhYkJ96RkVQP/OQbUmnIgK8mZCnygGdwmV8ZjFBaddBGpPT0+6du3a0s0QQgghWj2nS7MztYDMogqK3CNm5JRU8sORXHakFADQMciHgTHBjOgaRucQXzqF+BIX5kePqAD8vdtFdBCiSclvhRBCCNGOJOeWsj2lgDB/LzqH+NI52BdPq2Lj0TxW7TrOZ7szyCmprPUei4KEmBB+f1kvJvbtQN9OgVKWIcQZkEAthBBCtCEOp4uckkrK7U4qHE4q7C6yiitYezCbbw9kk5RbdtJ7vDwsVDpc+HpamdAnissHdKRbhL+pa/bzlJEzhDhHEqiFEEKIVkZrTVZxBUeySzmaU8rRnBKO5pRyJKeUY7llOFwnj2Lk62llVPdwbhndlcT4UEpsDo4X2kgrKCevtJLEuFDG9Y7C18vaAmckRPsmgVoIIYRoBYptdj7fncnKHelsTsqjtNJZvc7Lw0LXcH96RQVyef+OxIT64udlxdvDio+nhUAfTwZGB+PjKWFZiJYggVoIIYRoRpUOF2BCcU3llU4OZBaz93gR3+zP5uv9WVQ6XMSE+jJ9WAw9ogLoGuFP1wh/Ogf7SkmGEK2YBGohhBCiCRXZ7GxJzmfj0Tw2Hc1jZ2ohlU4Xgd4ehAV4EebvRWG5naScUqoqNyIDvZkzPJarB3VmaGyIPBAoRBsjgVoIIYQ4Sy6XJrPYxrZjBWw8msfGo3nsyyjCpcHDohgQHczNo+MJ9PYgt7SSPPdXZIA3Vyd0pm+nQPp2CqJLqJ/0QAvRhkmgFkIIIRohraCcdYdy2Hg0j2N5ZaQXlJNZZMPuNN3Mvp5WhsSGcNeEnozoGsbg2BD8vOS/WSEuBPKbLoQQQtRRVungQGYJe48XsSutkB8O53I0pxSAcH8vukcGMCwu1D3Osw8DooMZEB2Mp9Vymj0LIdojCdRCCCEuGE6XJr2gnPAAr1q9x7klFaw/nGt6oJPyOJpTinbXNwd4ezC8axg3jIhlTM8IeneQSU+EELVJoBZCCNHuFZRV8u6mFN7+IZm0gnLABOWoIG+sSnEwqwSAQB8PRnQN45pBnenbKYi+HYOICZURNoQQpyaBWgghRLtQbLOzYlsa+zKK8ff2wN/LA39vK4ezS/hgWxo2u4uR3cK4fWw3iiscZBVVkFVso7zSyZQh0VzcPZyB0cF4SNmGEOIMSaAWQgjRpu1JL+KdDcms2JZGWaWTYF9PbHYnFe7xn308LUwdEs1NF8fTp2NQC7dWCNEeSaAWQgjR6mQW2Viy8RjLNqWQWVyBRYFSCosCi1LuL7OssNyOt4eFawZ1Zu7IOAZ1CQHA4XRRWunEy2qR6baFEM1KArUQQohWIbu4gp2pBby3JZXP92TidGku7RXJtKExuLTGpUFrXf13l9ZoDbGMNswUAAAgAElEQVRhfkwbGk2In1et/XlYLQT7SvmGEKL5SaAWQghx3pVVOth4NI8fjuSyJ72IvceLyCmpBCDEz5NfjunKnOGxxEf4t3BLhRDi9CRQCyGEaDYVDicZhTbSCso5XmAjOa+MH4/ksu1YPnanxstqoXfHQMb3jqJPpyD6dgxkaFwoPp5SoiGEaDskUAshhDgrGYU2tqcUEOTrQbi/N2H+XnhYFFuP5fPjkVw2HM3jp7RCXPrEe5SC/p2DuHVMV0Z3j+Ci+DCpbxZCtHkSqIUQQjRaXmkln+w6zkc70tmYlFc9+UldXlYLg7uEcMe47sSH+xMd4kunEF86BftI77MQot2RQC2EEOKUjheW88WeTD7fncmPR3JxuDTdI/353cReXNorgnK7k7zSSnJLKim3OxkUE8KQ2BAJzkKIC4YEaiGEECfJLq5gxbY0Pt6Zzo7UQgC6Rfgz75JuXD2oE/06Bcn020II4SaBWgghBACVDhdr9mexfHMqa/Zn4XRpBsUE8z+TezOpX0d6RAW0dBOFEKJVkkAthBAXAJvdyeakfIpsdoJ9Pau/jhfa3A8Q5rIlOR+b3UVkoDfzLunKdcNi6BEV2NJNF0KIVk8CtRBCtFEOpwurRTVYenEku4Rv9mfz7YFsfjySWz0Vd11KQe8Ogcy6KJZLe0Vwac9IPKwyIYoQQjSWBGohhGhjtNYs/DGZv36yl3B/b8b2juTSnpGM6h7O0ZxSPt+dwed7MjmUVQKY2ufZw2MZ2yuSjsE+FJbbq79CfD0Z3jXspFkGhRBCNJ4EaiGEaEPySiv5n/d28uXeTC7pGYGfl5WV29NZvOFY9TZWi2JE1zBuHBnHhD5RdAnza8EWCyFE+yeBWgghWqHSCgd7jxdhsSi8PSx4e1hJyS/jvvd3kl9q55Gr+nHL6HiUUtidLrYm5/PDkVxiw/yY0CdKepyFEOI8kkAthBCtgM3uZEtyPj8czmX94Rx2phbicJ08a0q3SH9eu+kiBkQHVy/ztFoY0S2cEd3Cz2eThRBCuEmgFkKIFlBYbmd/RnF1gN52rIBK90OGCTHBzL+0G8PiQrFaFBUOFza7E4DL+nXAz0v+6RZCiNZE/lUWQohmoLUmv8xOUm4pybmlJOWUmT9zzZ/5ZXbAjLDRv3MQN10cx8XdI0iMDyXQx7OFWy+EEOJMSKAWQohzZLM7OZRVwt7jRezLKK7+M6+0snobpaBzsC/xEX5MHtCJ+HA/ukcGkBgfKvXOQgjRxkmgFkKIRtJak1lUwd6MIhOajxezL6OIw9mlON31zj6eFnp3CGRSvw707BBIfLgfceH+dAnzxdvD2sJnIIQQojlIoBZCiFMottn5Yk8mH+88zrZj+dWlGgDRIb707RTIpH4d6dspiD6dAokP98dqqX+iFSGEEO2TBGohhMD0PhfZHGQV2cgqriC9oJyv92Xx9b4sKhwuokN8uby/Cc59OwXRu2Mgwb5S6yyEEEICtRDiApdVbOOdH5JZtOEYuTVqngEiAryZPTyWqwd1YmhsaINTfAshhLiwSaAWQlxQKhxOCsvtpOWXs2jDMVZuT8fucjGxTwdGdgsjMtCbqEAfooK8iQvzw8NqaekmCyGEaOWaNVArpSYDzwFW4FWt9ZN11scCbwEh7m3u01p/0pxtEkJcOLTW/JRWxH+3pfLl3kyyiyuw2V3V6309rcwa3oVbRnela4R/C7ZUCCFEW9ZsgVopZQX+BVwGpAKblFIrtdZ7amz2ELBMa/2SUqof8AkQ31xtEkK0T1prcksryS2pJLe0grzSSo5ml/LhjnQOZZXgZbUwtnckk/v7EezrSbCvJyF+XlzSM0KGrBNCCHHOmrOHejhwSGt9BEAptRS4FqgZqDUQ5P57MJDejO0RQrRxFQ4nBzJK2JVWyIHMYo7llXEsr4yUvDIqHK6Ttr8oPpS/Th3Izwd2IthPHiAUQgjRPJozUEcDKTVepwIj6mzzJ+BzpdRdgD/ws2ZsjxCiDap0uHj7hyQ+2JbGgcxi7E4z3rO/l5XYcH+6R/ozvnck0SG+RAR6E+bvRbi/N1GB3oT6S++zEEKI5tecgbq+x+F1ndezgTe11v9QSo0CFiqlBmita3U1KaXmA/MBYmNjm6WxQojWRWvNpz9l8OSn+0jOLWNYXCi/HNONgdHBDIgOIjbMT0bdEEII0So0Z6BOBbrUeB3DySUdvwQmA2itf1BK+QARQFbNjbTWLwMvAyQmJtYN5UKIdsBmd5JRaCO9oJy0gnKWbU5hU1I+vToE8NatwxnbK7KlmyiEEELUqzkD9Sagp1KqK5AGzALm1NnmGDAReFMp1RfwAbKbsU1CiFbkeGE5H25PZ8W2NPZlFNdaFxHgxV+nDmRmYowMXSeEEKJVa7ZArbV2KKV+A3yGGRLvda31bqXUY8BmrfVK4PfAK0qpuzHlIDdrraUHWoh2LCWvjO8P5rBqVzrrD+eiNQyJDeHun/UiOtSXziE+dA72pXOIL14eEqSFEEK0fqqt5dfExES9efPmlm6GEKIRtNak5JWzLSWfH4/ksvZQDil55QDEhfsxZXA0U4dEEy9jQAshhGiFlFJbtNaJp9tOZkoUQjSp8konizYks+5QDjtSC8lzT+cd6OPByG7hzBvTjdE9wukeGSAPFQohhGgXJFALIZqE1ppVu47zxCf7SCsop2dUABP7RDE4NoTBXULo3SFQaqGFEEK0SxKohRBnrKCskmKbA6dL43BpckoqeObzA2xMyqNvpyD+MXMQI7uFt3QzhRBCiPNCArUQolG01nx/MIe31ifx9f4s6j5+Ee7vxRPTBjIzsQtWi5RyCCGEuHBIoBZCNEhrTWp+OV/vy+LtH5I4nF1KRIAXvx7XnbhwfzytCqvFgpdVMap7BMG+Mr23EEKIC48EaiFENYfTxaHsEnakFLDhSB4/HsklvdAGQEJMMP93/SCuHNgJbw9rC7dUCCGEaD0kUAtxgTucXcJb65PYmVrI3uNFVDhcgCnhGNEtjNu7hTOyWzg9o2RUDiGEEKI+EqiFuEC5XJqFPybzxOq9KBQJMcHcODKOAdHBDIwJpluEvwRoIYQQohEkUAtxAcootPGH93bw/cEcxvWO5KnpCUQF+bR0s4QQQog2SQK1EBeQlLwyVmxL45Xvj2B3ah6fMoAbRsRKT7QQQghxDiRQC9GOOJwuHl+1l+8PZtMtMoBeHQLoGRVIWaWTFdvS2JiUB8CYHhH875QBdJUpv4UQQohzJoFaiHaiwuHkd0u3s/qnDC7uHs6R7BK+3peF02UGjO4W6c+9k3px7eBouoT5tXBrhRBCiPZDArUQ7UBZpYPbFm7h+4M5PPTzvsy7pBsAlQ4XSbmlOF2aPh0DpbRDCCGEaAYSqIVo44psdm59YxNbj+Xz1PQEZl7UpXqdl4eFXh0CW7B1QgghRPsngVqINqakwsGW5Hy2JOWxOTmf7SkF2J0u/jlnKFcO7NTSzRNCCCEuOBKohWgDsopsfLE3k893Z7L+cA52p8aioG+nIK4bFsM1g6MZFhfa0s0UQgghLkgSqIVopbTWrD2Uw7/WHGLD0Ty0hrhwP26+OJ6xvaIYHBtCgLf8CgshRLtQmAof3gnxY+CSe6Gxz7zYyyF1EyStg+R1UJIFIV0gJBaC3X9WfflHgcXSuP1WlsGWN2DHEgjrBnFjIH40RPZt/D4uIPK/sRCtjNaabw9k8/xXB9l6rIBOwT7c/bNeXN6/I706yPTfQohWzmmH9G1g9YLOg5tmn1rDkTWgrO6gGANWz6bZd3NzOaE4AwpTTNiNHwN+YbW3Ob4DFl8Ppdlw5BvIOQTXvAAeXifvr7IMUjdC0loTotM2g7MSUNApASJ6mmOlbYXyvNrvtXpDQIfaYd3TF6ITTbviR4NfOGx6DdY/b9oTPQxSt8CeD832vqEQ0etESA+KhooiKDgGBSlQfBwSrofRC5ryKrZ6EqiFaEU2HMnlidX72J5SQHSIL49PGcB1iTF4e1hbumlCiPxk2LEU9n0ElaU1ViiI6gtxo00g6TAALO3od7aixAS40txTbKShINmEvJSNYC8DDx/47Q4I7Hjy5vZySNlgej2tp4kiLhd88nvY/PqJZcoCAR3Bs84Mr34RNXpku4Dd5g56x6DwGMRfApc9dnIYdzrgqz/Dvo9rL/cJhtiLzfc1dhT4hED2Xndv8FrI3A3a1XDbnQ4TMF32E8u8AmHEbTDqThOsD3wGy28xQfW272DfJ7DmcShKg+sXmuUVJbB3pfn5S15v9qcs0Gmw2VfcGIgdCb4htY9fUWxCbmHKietQklV7G1sh7F8F298xr61eJqB3Gw9j/whxo8wHmoJkc97HfoD8JPN9/um/oJ3mfb5h5ppbveCLh6GyBMbdXzu8l+fDpw+Y9sRdbH5nugw3od5ebnrpC5LN962ql90npPG99S1Iaa1bug1nJDExUW/evLmlmyFEkzqcXcKTq/fxxZ5MOgb5sGBiT2YMi8HLQ26rCdGinHbYtRy2LTIBCkwICOpce5vjOyD/qHldM4TFjYaOCacPjWdi13vwwz/BP/LEbf3wHtB9AnjVGWPeUQHbFpr2ewe4t3eHTQ/vho/hckHmLhOg0redCE2nE9X/xIeKj++G4fPhiidP3u6j35lygrDucOm9MHBm/dfI5YJVd8OWN2HUb6DnpBPhsDDV3TPrpl0mLBammHUuh1nu6W/O2y/MlER0Gw8z3zLfJzBh9f1fwoFPocdltUNpcYYpp3DYAAXegaY3Fsx17zzk1NdRWSGo04nr7ukLG182vb1e/tD7Cvjpfeg4EOYsO/HhY+cyU/4RGm96iPesBHuped3vWvPBoMsI8Alq3PfldFwuyNpjrk/OQUiYaYLu6TgdUJJp2uHtHlHK5YSVC0xAv+RemPCQCcQpG+G9W801jepz4sOIxdNc89Ls+o/hHWSu9fxv6u+xb2ZKqS1a68TTbieBWoiWk1NSwXNfHmTxxmP4eFj49fge3Dq6K75e7ah3S4izVVECK39j/kMdczeEdT2/xz+2wYTCrN0m+A2ebW5lh8TWv31hmgkkSWvNV95hs9wr0PTyxY02t9U7DTI9fulbzXbJ600wrNtjV59ti0zQiuhlglzBMbAVnDhO/2th0ByIHgpbF8La/4PidHNMq3v7kozGnb/F04S5qg8GIXGn3t4vrHYpw4d3ws7l8NvttT+AHN8J/7kUel1uemEzdpmgOOZu6H0lBESZ7Vwu+Pi3sPVtuOT3MOHhxvdUVpVZePqaHt6q921dCB//zly/OcvA4gGLZ0LmT3Dl03DRL0/el6MC0raYDxdFqRAz3HwfQ09zPU4lay9893fTw9vrcpj+mvnAU1PSOlg6x4TO/lPM9zV2ZJvora31vRtzt+ll/uoxU6pz3Rvm58pWaH7HkteanuvqD3ux5me7MPVEr3p5Hkx/tUVORQK1EK1YeaWT19cd5aVvDlNudzJneCy//VlPIgJO0dMhRGuiten53LUcLv0f6HpJ0+6/ohgWzYSUH02wczlg0Gy45B4I797w+4ozTTgK7mJ6YRsKpqdSlmdu/29509SHXvE36HPVmQeZouMnAnbyOsg5YJZ7BZjA5yg3r6P6mdvkGTtP9Nh1Gwtj7jFhtsrWhbDyLug2DmYvOXFutkJI3w4734XdK0xPZtVt+9hR5rZ9t3En2m+3mZDtrFGGUJ/gLif3eJ+J/CR4YRgk3gpX/t0s0xrevMr0hi7YaoLW/k/gmyfN+YMJu3GjTcjas8L8fI1/oOmC5OE1sOwX4OlnArWtAK57E3pe1jT7PxOlOaZUoqGH/ByV5meibmlLW+Bywap7zJ0IMD3r17xw4s5AGyGBWohWpsLhJCWvjE1J+Tz/1UGOF9q4rF8H/ji5Dz2iAk6/A9G6FGeY27kBkc2zf61NMOwwoHFBoug4rPq96TkbeUfz9mJVFJue213LTSixl5nes0n/C/4RZpuqeuMDn9a+LW+xQv9pcNG8k3vkqtiKYNF15lb79FdNKFz3nPmP2WmHoTfCxEdPfrBr78fw4a9NwKziH2luy1/2mKlzPp39q01oLcsz13Hc/Q2380yVZLkD9jpzHeLHmNIQ/3D3eRfCsR8h6XvY8S6UZplb+2P/B/KOwEe/he4TYdaihj8oVJbC3o9MnWv/adD10pbt0Vy5wIwSsWCb6Z3cvQKW3wQ/f6Z2b7DW5iG6pO/NNTr2oymtGHc/jLuv6duVucf0TLscpqe6U0LTH0OYUL3u/8zoIkPmto3e9TokUAvRwrTWfLM/m3d+TOZgVgmp+WW43L9ug2KCeeDKvozoFt6yjRRnx1YE/xpuehLvWNd0dYw1ffsUrPkL/OxP5pbpqWTuNr25xemmN6vXZJjy0smB80xoDRv+DQc/h5iLTpQi5ByA5Teb3sfxD8CIO2DtM7DueVMTOny+KWFIXgsoc4var8bPeWmO6XX2DYOLf2O2964xm6etEN6ZYW6xz3jd3OquUpxpShg2vmxqLif9BQbNMoH984dh43/MQ1oTHzaBuCDZBPt9H5sPARffZXo76+t1dVTCl3+CH/9l6lmnvGT+bCmVZbD1LVj77IkSjZ6TYObCttVbWXAMnh8KQ38Bl//F/N54B5mH70714KbLaXqoqz6gNYfKUvNz3lQfmES7JIFaiBaitWbdoVz+8cV+th0roHOwD8Piw+ga4U+3CH+6RfozoHMwFkvb+6Qu3D75HxPqAIbdBFc/17T7T14Pb/7c1MRWlsCtnzb8gNChr2DZTSYUzHnX9Ox9/pDpmZ3+GsQkmofKqmp1XXZ3OUScqVXsMvzk2mSn3fR2b33LbFOYeqIUAdz7frV2OULWPnN7N3ldjXrjWabsoq6UTfDt3+DQF+b2b2iN45dmm4ecZrwB/a6p/5wzfjI95KkbTQ9uRZF5KHDkr80HkLoPiZXmwBePwPZF5nwmPmqCd3CMCad5R83DUulbYfhtpqf9VA+anU/2clPqUZAMEx9pPe06Ex/fbc5hyFxzl+Gmj0zPuRBtgARqIVrA7vRC/vzRHjYezaNzsA+/mSCjdbQ7aVvhlQnmdrWnnxmrde5/ocfExu8jax/sWGx67yY8XLsmuCwP/j3GBKebPoY3JoMGbv++9ugDWpvA+/E9ppRhzjIIjjbr0reZYbgKjpn92MvM8si+phe5MMWEVjBDbw28zjyNH9nL9L4vvwkOf22WjX8QKovdpQhrTcAbd/+JMoWatDYPmQVFN+7WbuoW06tcXnBimbKYmttek079XpfLnP+XjwLK9Cj3ufLU70laa65Xzv4TywI6mJ5KixWu+WfDIV6cvcJUeH6IuZPQ9xozFJwQbYQEaiHOI5vdyXNfHeTl744Q6ufJXRN6Mmt4Fxk/urUoTINP/2jCWkis6Z0NjTe9ZGfS4+d0wKsTTP30bzaZURP+c6npRb5j/cljwNZUkGLqc3csNoFXWU0gR8NVz0LCdSaQLp0DB7+AeV+Y2t/UzfD65Wb0g5lvm6BacAw++YOpT+4+0TxQVbfsxFZkeoGd9hOjNNS8fW4vN+UQ298xkzjYy2HAdDP6QM5+06ahN57BRW4h5QWm97yx5S2OSjMRRtXoAQXJprxg3P3nNmqDOLXV95kRH3693vzuCdFGSKAW4jz54XAu9/93J0m5ZcxMjOHBK/sR7NdGZvBqD+w28x918loz7FXVkFtVnA5462oTYoOjTbB1Vph14T3hqmcaf/v5hxfhs/tNOcKAaWZZ2hZ49TIzAsWUf5llNSdBqBrloSDZrOs40DzAN/A602P3/i/NA2RDbjQ91V/+CSY/aR6Iq7LuOVOycMVTJvh++zdAwfj7TQ3zuY5xXJoD61+Aja+YntqZb0P38ee2TyFqcrncNdHy3IhoWyRQC9HMXC7N05/v58VvDhMb5scT0wYyukczPkAjarOXm2HNqh7aUhYTVm9eVfshtzV/NQF06ssw6HrzH3tpthlB4vMHzcN1CbNg0uOnHrGjMM08UBU7Em54r3ZJw1ePwff/MCUShakmRBemmHW+YWZ84fgxZuiyuiNNOB3wzRPm/WjodYUZEq3m/l0uWHwdHPrSvO5zlQnd9dUnn4vyfNODG9ihafcrhBBtlARqIZpRWaWDu9/dzme7M5k9vAuPXNVfJmM5n/atMg86lWSaUoaxfzSTLyyZZXqb5ywzM2od/Q7eusb0Hk996eT92MtNkF377IkRKgbNql3T7HTAkW9MKM/YCb/+8eSH+BwVpq468ycz9XH8aDMVcPwYiOzT8BizNR3+2gyVNvmJ+ssXSrJN73j/aaevFRZCCNEkJFAL0UwyCm388q1N7D1exIM/78eto+NRbXBszWZVcMwMleblf/ptnQ5Y96yZ7jZ2pAmh4T3qf6hNa/jxJfjsATNu7OV/NdtX2bbIjEM8cKZZ9+8xprd6/jenHhore78Zdu3QF6Yet8sIM/VufpKZ6a0kw8y2NukvMOSG+vdRlgdluQ23XQghRJsjgVqIJpZTUsGafVn8/bP9lFU6eWH2EMb3iTr9G1tS9gEzqUJBsgmJcaPNrGxVPaZOhxmVQbuaZlpnlwvWPwdf/a95QG/Ub2D4r2qXYNRUmArv/fLEuMTleWZ5QAfoNt6UaHQda+p6XU749H4zKkSfq2DaK/WPJ/z9P0wJhn+UGdN43peNn7ShKN3MNrd9iXkwz+Jhxv4dNNtMD9wWhywTQghx1iRQC9EEMgptvLclha/2ZbE9pQCtoWuEPy/NHUqfjs0wmUdTsBWZULhjiXlgTllNQC1ON+t9Q83UvkXH3WHaaZaPvNM9hq/X2R23JBs+uA0OfwV9rzYPCx76whxv1J2mVCG4y4n9718NK+4wo1Bc9SwMnAG5h83DhUlrzYQitkIzBFvCTDPU3IHVJqRf9ljDk0JoDavd40Rf8XcYMf/Mz0VryN5nxltuzoklhBBCtGoSqIU4Ryt3pPPgB7sotjkYFBPMhD4dmNg3iv6dg1pviUfOIVg0A/KPQlR/M7nGwJnmIbOCY2bUiaS1ppQhqLN7CLlYUxu86VUzTNuMN2r3VjvtZia+/KQTQ40VHzclHSHuCUKUBT570DzUdsWTMOwWU/aQugW+e8oM7waAgsBOZiSO49uhY4IZ8q1mzXIVuw32f2I+GBz6CtBmlIvhvzr9dXC5zIx+kb2l/EIIIcRZk0AtxFkqttl59MPd/HdbGkNiQ3hm5mC6RjSiFrilJa83YxgrC1z3lqktPpMwuWclrPyN6Z392aNmfN/kdXBsA9hLT2znHQyBHU15Rmn2ieXhPU047jjg5H1n7ob07Wbki6pQHj3UTBrSmDKK4kxwlMv4tUIIIc4rCdRCnIUtyXn8dul20gvKuWtCT+6a0AMP63me5bAsz/QKB0TVDsSFqaaH+dh6M6FIzck6dr1nyidCYuGG5RDW7eyOnZ9spmBOc/+ORfUzx4gbZcpEgrvUnrykssy0qyTTBOTGPIQohBBCtBESqIU4A1prXvn+CH/7dD+dQ3x49vrBDItr5MxrTenQV6aX2WEzoTmki6khLkg2JRdgeoidlabHFkzPcO5BiL0YZi1q/IxxDXFUmtrriF4yCYMQQogLWmMD9TlOryVE21dYZuf3y3fw5d5MrhjQkb/NSCDIpwVmOjz4pQnTkb1g6E0nSiMKU0w99PD5poyjwwAz4kX6Nkj63pR6dJ8Ak/63aUah8PAyPdJCCCGEaBQJ1OKCtiOlgDsXbyWj0MYjV/XjlpYaU/rAZ/DuXDMJyC8+PH0vs8UKsSPMlxBCCCFalARqcUHSWrPwx2Qe/3gvkYHeLLt9FENjQ1umMfs+gWW/gA794RcrzDBzQgghhGgzJFCLC06xzc59/93Fqp3HGd87kmdmDibU/yzHXj5btkLY86GZQOTYeug8FG78oPYDf0IIIYRoEyRQiwvKnvQi7ly8lWN5Zfxxch9uu7QbFst5LPHI2AXrnoe9K82Dh+E9YeIjcNGvwKeVThQjhBBCiFNq1kCtlJoMPAdYgVe11k/WWf9/wHj3Sz8gSmstXXSiyWmtWbY5hUc+3E2wryeL541gRLfzOIJF+nb47u+w72PwDoLBN8DgORA9TCYeEUIIIdq4ZgvUSikr8C/gMiAV2KSUWqm13lO1jdb67hrb3wUMaa72iAtXWaWDh1b8xH+3pjG6RzjPzRpCREATjIbRGCVZ8NFvzYx/3sEw9j4YebvUSQshhBDtSHP2UA8HDmmtjwAopZYC1wJ7Gth+NvBoM7ZHXIAOZRXz60VbOZhVwm8n9mTBxJ5Yz1eJR3EmvHW1Gfpu/IMw4jbwCT4/xxZCCCHEedOcgToaSKnxOhWod4wvpVQc0BX4uhnbIy4wSTmlTHtxPZ5WC2/fOpxLekY27QEcFbB/NeQcgEGzzSQsVYozTJguTIO575nxo4UQQgjRLjVnoK6vG7ChaRlnAe9prZ317kip+cB8gNjY2KZpnWjXSisc3LZwCxaL4oNfjyY23K9pdqy1mUVw+2L46X2wFZjl3z4FQ26AMfeA1dOE6eIME6bjLm6aYwshhBCiVWrOQJ0K1OiyIwZIb2DbWcCdDe1Ia/0y8DKYqcebqoGifdJa84f3dnAwq5i3bh1+5mHa6QBrnV+NwlTYsdR85R4ED1/oe5XpmQ7vAeufh61vw7Z3wDcM7OUw932IHdl0JyaEEEKIVqk5A/UmoKdSqiuQhgnNc+pupJTqDYQCPzRjW8QF5N/fHuGTXRncf0WfMyvzqCiBd2+AI99CYCcIiTVlHCVZcPQ7QEPsxTB6AfSbUnuYu5//w/ROr3sODn8FsxZBl+FNfm5CCCGEaH2aLVBrrR1Kqd8An2GGzXtda71bKfUYsFlrvdK96WxgqdZaep7FOfv2QDZPfbaPqxI6Mf/Sbo1/Y0UxvDMDUjeZhwcris3DhCkbwOoFY/8Ig2ZBWNeG9xEcDVc+de4nIVAeYukAACAASURBVIQQQog2pVnHodZafwJ8UmfZI3Ve/6k52yAuHDtTC7hr8VZ6dwjkqRkJqMaO72wrgnemm9roGa9B/6nN21AhhBBCtCsyU6JoF7Yey+em1/6/vTuPsqus83///lZlnqcKgQxkhBACBBJDAAFBRlGwRRRsBRFFbRGvM15tf7+2+7p+2r1a2wvtFRXFAQEBbZQwhIDMkBEyB4qMlYTM81xVz/3jHLQMFXKSqlP7nKr3a61adfY+u059arNDffLkOc+eRs8u7fnptRPo0qHAS3vP1lyZXj0brvoljLm8qDklSVLrY6FW2Zu2dBPX/2IaVd07ctenJnFMr86H/qK6Wph7b251jq01cNWduTcZSpIkHSYLtcra89UbuOHOGRzTqxN3fWoSR/Xo9PZfULc/t1LHM/8Bm5fBgJNzq3EMP7dF8kqSpNbHQq2yNX/1Vq7/5XSG9u3Kbz55OlXd3+Z24usX59aOnnMPbF8DR4+Dq38Hx18Khc61liRJaoSFWmVp+5793HTXbHp36cBvP3U6/bodpEzPux+evxVWz4KohJEXwPv+C0ZdZJGWJEnNwkKtspNS4hsPzGXFpl387lOTDl6m186H+26AquPh4u/CSVdBt/4tG1aSJLV6FmqVnbumreDPc9bw1YuPZ+KwPgc/8PF/gY494PqHocvbHCdJktQEFVkHkA7HgtXb+Jc/LeCc46r47LkjDn7gsmfhtUfh7C9apiVJUlFZqFU2tu/Zz+fumkXvLu35wYdOoaLiIHOgU4Ip/wu6HwOnf6ZlQ0qSpDbHKR8qC/X1iS/e8zIrNu3irk+eTt+DzZsGWPgnWDUDLr8V2hewJrUkSVITOEKtsvDDx1/l8YXr+OfLTuD04X0PfmBdLUz9F6gaDadc03IBJUlSm+UItUreI/PW8KMnqrlq/CCuO3Po2x88+9ewsTq3xnSll7ckSSo+G4dK2qI3tvGle19h3OBe/Ns/jCUarh299GmY/FXYtelv+/ZsgcGTcjdskSRJagEWapWsrbv2c+OvZtKtYzt+8rHxdGxXmXuivg6e+h489X3oOwJGX/a3L6psD5M+601bJElSi7FQq2T9n0cWsWrLbu799Bkc1aNTbue21XD/p2D5s3DKR+A9/w4du2UbVJIktWkWapWkWSs287tpK7jhncMYf2zv3M4N1XDHRbB/N7z/xzDuI9mGlCRJwkKtElRbV883/zCPAT068cULj8vv3Av3fTy3xvSNf8ndTlySJKkEWKhVcu58YTkL12zjv//xNLp1zF+iU74Nb8yFa+6xTEuSpJLiOtQqKW9s3cN/PraYc4+r4tKxA3I7Fz0EL/1/MOmf4PhLsg0oSZJ0AAu1Ssq//nkBtfWJ71xxYm6JvK018Md/gqNPgQv+d9bxJEmS3sJCrZLx/OsbeGjuGj533kiO7ds1d9fD+z8J9bXwwV9Au7e53bgkSVJGnEOtkvGTp5bQr1tHbjxnOOzdDvd9Ala8AB/4aW69aUmSpBLkCLVKQvW67Tz16nquPeNYOu1eC7+4FKqnwnt/CCd/KOt4kiRJB+UItUrCHc8to0O7Cq4dtg1+ejns3QYfuRdGXZB1NEmSpLdloVbmNu/cxwOzavjs6D30uvsK6NgdPvEIDDgp62iSJEmHZKFW5u6atoI9++u5vsPjkOrgk49Dz4FZx5IkSSqIc6iVqX219fzqhWWcO6InvZY+BKMvs0xLkqSyYqFWpibPXcPabXv58vAa2L0ZTroq60iSJEmHxUKtzKSUuOO5pQyv6spJm6dA5z4w4vysY0mSJB0WC7UyM2P5ZubUbOVTpx9FLJ4MJ/4DVLbPOpYkSdJhsVArM7c+UU3vLu35QJeXYf8up3tIkqSyZKFWJmat2MxTr67nxnNG0HHhA9BzMAw+PetYkiRJh81CrUz81+Ov0btLe649pWvujohjr4QKL0dJklR+bDBqcTOX/210umv1n3NrTzvdQ5IklSkLtVrcf019jT5dO3DtGcfC3Pug6gQ46sSsY0mSJB0RC7Va1Mzlm3n61fXceM5wuu5eDStegJM+CBFZR5MkSToiFmq1qL+OTk8aAk99P7dz7JXZhpIkSWoCC7VazJuj058+Zzhd5twJs38N7/wS9BmWdTRJkqQjZqFWi7nz+WX07Nye6wauhoe/DqMugvO/lXUsSZKkJrFQq0Xs2V/H4wvXcvVxQac/XA+9h8KVP4OKyqyjSZIkNUm7rAOobXhy0Trq9u3m8+v/HWr3wtW/g049s44lSZLUZEUdoY6ISyJicURUR8QtBznmQxGxICLmR8Rdxcyj7Px5zhq+2fkBum5aAB/4KVQdl3UkSZKkZlG0EeqIqARuAy4EaoDpEfFgSmlBg2NGAd8AzkopbY6I/sXKo+zs3FvLzEXV/KD9Y8RJH4LjL8k6kiRJUrMp5gj1RKA6pbQkpbQPuBu44oBjPgXcllLaDJBSWlfEPMrIE4vWcU16mA71e+CdX8w6jiRJUrMqZqEeCKxssF2T39fQccBxEfFcRLwYEQ5dtkJTXq7m4+0eIx1/GfQ/Ies4kiRJzaqYb0ps7NZ3qZHvPwp4FzAIeCYixqaUtvzdC0XcCNwIMGTIkOZPqqLZvmc/x1TfTc/KHXD2l7OOI0mS1OyKOUJdAwxusD0IWN3IMf+TUtqfUloKLCZXsP9OSun2lNKElNKEqqqqogVW83ti3go+UfEQ244+CwaNzzqOJElSsytmoZ4OjIqIYRHRAbgaePCAY/4InAcQEf3ITQFZUsRMamHbXriT/rGFbhd8LesokiRJRVG0Qp1SqgVuAh4FFgL3ppTmR8R3IuLy/GGPAhsjYgHwJPDVlNLGYmVSy9q6czfv2nAXNV1PpGL4uVnHkSRJKoqi3tglpTQZmHzAvm83eJyAL+U/1MosmvILTo/1vH7GdyEam1IvSZJU/rz1uIqm86IHqIkBDD/zyqyjSJIkFY2FWkWxedtORuyew9qqs4iKyqzjSJIkFY2FWkUx44WpdI29VJ307qyjSJIkFZWFWkWxaf4TAAw+9aKMk0iSJBWXhVrNbsOOvRyzZQbrO48gurluuCRJat0s1Gp2j81Zyfh4lcrhZ2cdRZIkqeiKumye2qZFM/9Cl9hL5xPPzzqKJElS0TlCrWa1btseeq59kUQQQx2hliRJrZ+FWs1q8tw1TIoF7Ot7AnTpk3UcSZKkorNQq1k9Omc5Eypfo+NIbzUuSZLaBgu1ms2arbupWzGDjuyDYU73kCRJbcMhC3VE3BQRvVsijMrbQ3PWcEbFAhIBx56ZdRxJkqQWUcgI9QBgekTcGxGXREQUO5TK05QFa3l3p8XEgJOgs38HkyRJbcMhC3VK6VvAKODnwMeB1yLiuxExosjZVEb27K9j/sp1jKl/FYadk3UcSZKkFlPQHOqUUgLeyH/UAr2B+yLi+0XMpjLy8sotnFS/mHZpH7hcniRJakMOeWOXiLgZuA7YAPwM+GpKaX9EVACvAV8rbkSVgxeXbMzNn44K4tgzso4jSZLUYgq5U2I/4AMppeUNd6aU6iPivcWJpXIz4/V1fK/Di8Qx46FTz6zjSJIktZhCpnxMBja9uRER3SPidICU0sJiBVP52Ftbx8ia+xlYvwbO/krWcSRJklpUIYX6x8COBts78/skAOYuWc3nKu5nU78JcNzFWceRJElqUYUU6si/KRHITfWgsKkiaiNqn7uVqthK+0v+FVxVUZIktTGFFOolEXFzRLTPf3wBWFLsYCoTOzdwyoo7ebb9GXQf6c1cJElS21NIof4McCawCqgBTgduLGYolY+6v3yf9vV7mT3q5qyjSJIkZeKQUzdSSuuAq1sgi8rNpqXEzDu4p+5djBpzatZpJEmSMlHIOtSdgBuAE4FOb+5PKX2iiLlUDp76HnVU8oPaK3l0WN+s00iSJGWikCkfvwYGABcDTwGDgO3FDKUyUF8HiybzXOd30eeoIfTp2iHrRJIkSZkopFCPTCn9M7AzpXQncBlwUnFjqeStnQd7tzJ5+0hOH94n6zSSJEmZKaRQ789/3hIRY4GewNCiJVJ5WPYcAE/vO55Jw53uIUmS2q5C1pO+PSJ6A98CHgS6Af9c1FQqfcufY2unQbyxpy8ThzlCLUmS2q63LdQRUQFsSyltBp4GhrdIKpW2+npY/jxzKicwqn83+nXrmHUiSZKkzLztlI/8XRFvaqEsKhfrF8HuTUzePoIzRjjdQ5IktW2FzKGeEhFfiYjBEdHnzY+iJ1PpWp6bP/3M/uM5Z1RVxmEkSZKyVcgc6jfXm/5cg30Jp3+0XcueZVuH/qzd398RakmS1OYVcqfEYS0RRGUiJVj+PDMYw/hj+9C1YyF/J5MkSWq9CrlT4rWN7U8p/ar546jkbayGnet4bP/lnH2G0z0kSZIKGV58R4PHnYB3A7MAC3VbtOxZAF6qP4GPHmehliRJKmTKx+cbbkdET3K3I1dbtPw5tlX2YVvnIYw5ukfWaSRJkjJXyCofB9oFjGruICoDKZGWPceL9aN553FVVFRE1okkSZIyV8gc6j+RW9UDcgV8DHBvMUOpRG1eRmxfzdP7L+Zsl8uTJEkCCptD/R8NHtcCy1NKNUXKo1KWX396Wv1obh7VL+MwkiRJpaGQQr0CWJNS2gMQEZ0jYmhKaVlRk6n0LHuO7RU9qOw/mv49OmWdRpIkqSQUMof690B9g+26/D61JSlRv+wZXqg9nrOPPyrrNJIkSSWjkELdLqW0782N/OMOxYukkrTxdSq2ruTpurHeblySJKmBQgr1+oi4/M2NiLgC2FDIi0fEJRGxOCKqI+KWRp7/eESsj4iX8x+fLDy6WlT14wC8WDGOCUN7ZxxGkiSpdBQyh/ozwG8j4tb8dg3Q6N0TG4qISuA24ML810yPiAdTSgsOOPSelNJNh5FZGUivT2VVHM0xw8bQqX1l1nEkSZJKRiE3dnkdmBQR3YBIKW0v8LUnAtUppSUAEXE3cAVwYKFWqdu/h7T0GR7ffzYXjnH+tCRJUkOHnPIREd+NiF4ppR0ppe0R0Tsi/q2A1x4IrGywXZPfd6ArI2JORNwXEYMLzK2WtOIFKmp382w6mUtOHJB1GkmSpJJSyBzqS1NKW97cSCltBt5TwNc1dhu9dMD2n4ChKaWTgceBOxt9oYgbI2JGRMxYv359Ad9azSlVT2Uf7dg/+CyqunfMOo4kSVJJKaRQV0bEX1tURHQGCmlVNUDDEedBwOqGB6SUNqaU9uY3fwqMb+yFUkq3p5QmpJQmVFW5wkRL27f4MabXHc8FpwzPOookSVLJKaRQ/waYGhE3RMQNwBQOMpJ8gOnAqIgYFhEdgKuBBxseEBFHN9i8HFhYWGy1mG2r6bhpMU+nk7l4rNM9JEmSDlTImxK/HxFzgAvITeN4BDi2gK+rjYibgEeBSuCOlNL8iPgOMCOl9CBwc35JvlpgE/DxI/5JVByvPwHApgFn07+7d0eUJEk6UCHL5gG8Qe5uiR8ClgL3F/JFKaXJwOQD9n27weNvAN8oMIMysH3eI+xKvTjptDOzjiJJklSSDlqoI+I4ctM0rgE2AveQWzbvvBbKpqzV19F++VM8XT+OS8YefejjJUmS2qC3G6FeBDwDvC+lVA0QEV9skVQqDatn06l2G6v6nEn/Hk73kCRJaszbvSnxSnJTPZ6MiJ9GxLtpfCk8tVIbX3mI+hQcNe6SrKNIkiSVrIMW6pTSH1JKHwZGA38BvggcFRE/joiLWiifMrRv0RTmpOGcP/6ErKNIkiSVrEMum5dS2plS+m1K6b3k1pJ+Gbil6MmUrZd/x9Hb5zKvxzkc5XQPSZKkgypkHeq/SiltSin9JKV0frECqQSsmkn60xd4vm4MeyZ8Nus0kiRJJe2wCrXagO1r4e6PsqtDPz63/2bOPM7VPSRJkt5OoetQqy2o3Qv3fgz2bOHHg/5fYl9PRg/onnUqSZKkkuYItf7m4a/BypdIV9zG71f14owRfamocGEXSZKkt2OhVs6O9TDzl3D6Z3i9/0Ws3baXd47sl3UqSZKkkmehVs7aebnPx1/Kc9UbADhrhIVakiTpUCzUylm3IPe5/4k8V72BQb07M6Rvl2wzSZIklQELtXLWLoCuVdR16ceLSzY6Oi1JklQgC7Vy1s2H/mOYt2or2/bUcubIvlknkiRJKgsWakF9HaxbBEedyLP5+dNnOkItSZJUEAu1YPMyqN0N/cfw/OsbGD2gO1XdO2adSpIkqSxYqAVr5wOwt+9oZizb7Oi0JEnSYbBQK7/CRzB79wD21tZzlvOnJUmSCmahVm6Eus8wnl62k8qKYOKwPlknkiRJKhsWauVGqPuP4bnXNzJucC+6d2qfdSJJkqSyYaFu6/bvhk1L2NNnNHNrtnDWCKd7SJIkHQ4LdVu3fhGkel7ZP5D6BOeN7p91IkmSpLJioW7r1uZuOf7Iur5Ude/IKYN6ZRxIkiSpvFio27p1C0jtOnP/sg5ccEJ/Kioi60SSJEllxULd1q2dz44eI9i2t54LTjgq6zSSJEllx0Ld1q1bwGsMoXP7Ss4a6Q1dJEmSDle7rAMoQzs3wo61PFPZn7NH9aNT+8qsE0mSJJUdR6jbsnW5W45P3300F45xuockSdKRsFC3ZfkVPl5Ngznf5fIkSZKOiIW6LVs3n63Rg2OHDKVvt45Zp5EkSSpLFuo2bN/qecyvHcQFYwZkHUWSJKlsWajbqvp6Yv1CFqfBzp+WJElqAgt1W7XpddrX7WZD11EMr+qWdRpJkqSyZaFuo3YvmgJAt+PPyziJJElSeXMd6jZqy5xHeKP+KE6fMD7rKJIkSWXNEeq2qHYvfda/xKz2p3Hq4F5Zp5EkSSprFuo2aNurz9Ax7aF+xAVERNZxJEmSypqFug2qmf5n9qVKxp71nqyjSJIklT0LdRvUbeVfmNfuREYPOTrrKJIkSWXPQt3GbFi9jCG1S9kx6Fyne0iSJDUDC3Ubs+jZPwBw7MT3ZZxEkiSpdShqoY6ISyJicURUR8Qtb3PcByMiRcSEYuYR8PoTbIreHDtmYtZJJEmSWoWiFeqIqARuAy4FxgDXRMSYRo7rDtwMvFSsLMqp2bidsXtmsrb/WeB0D0mSpGZRzBHqiUB1SmlJSmkfcDdwRSPH/SvwfWBPEbMImP7cVHrFTqrGXZZ1FEmSpFajmIV6ILCywXZNft9fRcSpwOCU0p+LmEN5Oxc+Rj1Bv1MuyTqKJElSq1HMQt3YnIL01ycjKoAfAF8+5AtF3BgRMyJixvr165sxYtuxdMNOTtg5jQ09xkCXPlnHkSRJajWKWahrgMENtgcBqxtsdwfGAn+JiGXAJODBxt6YmFK6PaU0IaU0oaqqqoiRW6+psxYzLqrpfMJFWUeRJElqVYpZqKcDoyJiWER0AK4GHnzzyZTS1pRSv5TS0JTSUOBF4PKU0owiZmqztrz8IJWR6D7W+dOSJEnNqWiFOqVUC9wEPAosBO5NKc2PiO9ExOXF+r56q2UbdvKO7VPZ3ukYGOTKhJIkSc2pXTFfPKU0GZh8wL5vH+TYdxUzS1v25Kx5fKxiHrtP+rzL5UmSJDUz75TYBux9+X7aRT3d33FN1lEkSZJaHQt1K7di4y7eseMJNnYbBf1PyDqOJElSq2OhbuWenjad8RWvUXnyh7KOIkmS1CpZqFu5+jn3AdBr4tUZJ5EkSWqdLNSt2MqNO5m0cypreo6DXkOyjiNJktQqWahbsRdffJrjKlbR8TRHpyVJkorFQt2KVcz7PbVU0meC86clSZKKxULdSq3cuINJu/7Cqr5nQNe+WceRJElqtSzUrdTMZx9mYGyk63jXnpYkSSomC3Ur1XH+veyOTvQb//6so0iSJLVqFupW6NWadZy19xlWHX0RdOyWdRxJkqRWzULdCi166h56xG76nXVd1lEkSZJaPQt1K5NSot/rf2BjZRW9Tjg/6ziSJEmtnoW6lZmz6FUm1s1mw/D3Q4X/eSVJkorNxtXKrH7217SLega96/qso0iSJLUJFupWZH9dPcNW/YllHUfTdeCJWceRJElqEyzUrcjs6c8ymmXsHuOdESVJklqKhboV2THtt+ynkhHnXZt1FEmSpDbDQt1K7N6zl5M2PsKrPc6kQ4+qrONIkiS1GRbqVmL2U3+kKrbQ7tSPZB1FkiSpTbFQtxLbX/kTu+nIqLM+kHUUSZKkNsVC3QpUr9vBcTumsbbPO6jo0CnrOJIkSW2KhboVePjp5xlWsZZ+4y7LOookSVKbY6Euc3v217Ft3qMAdDvx4ozTSJIktT0W6jL30Jw1TKybzZ5ug6HP8KzjSJIktTkW6jJ370uvc1blfDqOvggiso4jSZLU5lioy9iiN7YRNdPowh5i5LuzjiNJktQmWajL2F0vreC8dnNJFe1g6NlZx5EkSWqT2mUdQEdm175a/jBrFQ93nk8MmASdemQdSZIkqU1yhLpM/c/Lq+m0dwOD9lbDyPOzjiNJktRmWajLUG1dPT956nWu6fdabsfIC7INJEmS1IZZqMvQQ3PXsGzjLq7u/Rp0rYKjTso6kiRJUptloS4z9fWJ/37ydY7v34WjN74AI86HCv8zSpIkZcUmVmamLFzL4rXb+ca4fcSujU73kCRJypiFuoyklLjtyWqG9OnCOWk6EDD8vKxjSZIktWkW6jLyzGsbmFOzlX8651gqXv5NbnS6W1XWsSRJkto0C3UZufWJagb06MSV3efB9jUw4fqsI0mSJLV5FuoyMW3pJqYt28Snzx1O+1m/hO7HwKiLs44lSZLU5lmoy8TPn11Cn64duGZkPbz+BJx2LVR6o0tJkqSsWajLwLpte3h84TquGj+ITnN/DRG5Qi1JkqTMWajLwO9n1lBXn7h6/ACY/Rs47lLoOTDrWJIkScJCXfLq6xO/m7aCM0f0Zdj6J2Hnet+MKEmSVEKKWqgj4pKIWBwR1RFxSyPPfyYi5kbEyxHxbESMKWaecvRM9QZqNu/mmolDYOYvoNeQ3N0RJUmSVBKKVqgjohK4DbgUGANc00hhviuldFJKaRzwfeA/i5WnXP3upRX06dqBiwdsh6VPw2nXQUVl1rEkSZKUV8wR6olAdUppSUppH3A3cEXDA1JK2xpsdgVSEfOUndybEdfywdMG0uGZ70FFOzj1Y1nHkiRJUgPFXHdtILCywXYNcPqBB0XE54AvAR0A5zI08PuZNdTWJz7d4WGYfj+c9y3oflTWsSRJktRAMUeoo5F9bxmBTindllIaAXwd+FajLxRxY0TMiIgZ69evb+aYpam+PnH39BXceMwy+j7/b3DC5XDOV7KOJUmSpAMUs1DXAIMbbA8CVr/N8XcD72/siZTS7SmlCSmlCVVVVc0YsXQ9W72B2LyMr2z/HlSdAO//cW79aUmSJJWUYhbq6cCoiBgWER2Aq4EHGx4QEaMabF4GvFbEPGXlj9MWc0fH/6R9uwq4+rfQsVvWkSRJktSIos2hTinVRsRNwKNAJXBHSml+RHwHmJFSehC4KSIuAPYDm4HripWnnOzcW8tpr/6I4RWriA8+AH2GZR1JkiRJB1HMNyWSUpoMTD5g37cbPP5CMb9/uXp8wWouiRfYPPQy+o44L+s4kiRJehveKbEELZz+BP1iG73HfyDrKJIkSToEC3WJ2bp7P/1WTqEu2lEx6oKs40iSJOkQLNQl5rF5a3h3TGfnwLOgU4+s40iSJOkQLNQlZuaslxhWsZbup1xx6IMlSZKUOQt1Cdm0cx/9Vk4BII5/T8ZpJEmSVAgLdQl5eN4aLqiYzq7+p0KPo7OOI0mSpAJYqEvIs7PmMK5iCZ3Hvi/rKJIkSSqQhbpErNu2h741UwGIE96bcRpJkiQVykJdIh6au4aLKmawr+cw6Hdc1nEkSZJUIAt1iXhs5qucUbmQDie+DyKyjiNJkqQCWahLwILV2+j3xtO0pxZGO91DkiSpnFioS8A901dwabsZ1HepgkETso4jSZKkw2Chztie/XU8Nvs1LqicRcWYy6GiMutIkiRJOgwW6oxNnruGd+5/ng5pH4z7SNZxJEmSdJgs1Bm7e9pKPtrxOVLfkTBwfNZxJEmSdJgs1BmqXreD1csXcUr9fOKUa1zdQ5IkqQxZqDN0z/QVXFn5XG7j5A9nG0aSJElHpF3WAdqqvbV13D+zhkc6Pw8Dz4Zeg7OOJEmSpCPgCHVGpixYy9Dd8+m/fxWcck3WcSRJknSEHKHOyD3TV/KxLi+QojMx5vKs40iSJOkIOUKdgTVbdzOteg2X8jxxwvugY/esI0mSJOkIWagz8MfZqzkvZtOpbjuMc7qHJElSObNQt7CUEg/MquFT3Z6H7kfDsHOzjiRJkqQmsFC3sHmrttFu/XzG75sGp13nrcYlSZLKnIW6hd0/q4YvtX+A1LEHTPps1nEkSZLURBbqFrSvtp5XX36WCyumE2fcBJ17ZR1JkiRJTWShbkFPvbqe6/ffzf72PWDSZ7KOI0mSpGZgoW5BM56fyoWVs6g46/PQqWfWcSRJktQMLNQtZMuufZyx4nZ2Vfag0tFpSZKkVsNC3UJeePpR3lUxm22nfRY69cg6jiRJkpqJhbqF9J/1Q7ZED4664PNZR5EkSVIzslC3gFWrVzFu70xeH3wV4W3GJUmSWhULdQtY8NyDVEZi0OnvzzqKJEmSmpmFugVE9VR2RFeOGn1m1lEkSZLUzCzURbZiw07G7pnB2qozobJd1nEkSZLUzCzURfb8i88wIDbT+6RLso4iSZKkIrBQF9nO+Y8C0OfkSzNOIkmSpGKwUBfR0g07OW7HNDZ1HQE9B2YdR5IkSUVgoS6ix15ewsSKRXQ4/sKso0iSJKlIfJdcEdXMnkLHqKXjiRdnHUWSJElF4gh1kVSv28HwrS9SW9EJhrhcniRJUmtV1EIdEZdExOKIqI6IWxp5/ksRsSAi5kTE1Ig4tph5+e02mAAADXxJREFUWtLkuWs4t2IOdUPOgvadso4jSZKkIilaoY6ISuA24FJgDHBNRIw54LDZwISU0snAfcD3i5WnJdXXJ6bPnsXwijV0HO38aUmSpNasmCPUE4HqlNKSlNI+4G7gioYHpJSeTCntym++CAwqYp4W85uXljNk84u5jZEXZBtGkiRJRVXMQj0QWNlguya/72BuAB4uYp4WsXTDTr47eSEf6LGY1HMw9B2ZdSRJkiQVUTFX+YhG9qVGD4z4KDABOPcgz98I3AgwZMiQ5srX7OrqE1++92V6Vu7j1LpXiJEfhGjsNEiSJKm1KOYIdQ0wuMH2IGD1gQdFxAXAN4HLU0p7G3uhlNLtKaUJKaUJVVVVRQnbHG5/egmzVmzhJ+OWULFvB5x8ddaRJEmSVGTFLNTTgVERMSwiOgBXAw82PCAiTgV+Qq5MrytilqJb9MY2fjDlVS498ShOWX0vDDgJhkzKOpYkSZKKrGiFOqVUC9wEPAosBO5NKc2PiO9ExOX5w/4d6Ab8PiJejogHD/JyJa2uPvGle16hR+d2/J/x24h1C2Dip53uIUmS1AYU9U6JKaXJwOQD9n27weNWsQTGM6+tZ8Gabfzgw6fQc+4t0LkPnPTBrGNJkiSpBXinxGbw+5k19OrSnvcMqYNFD8Fp10L7zlnHkiRJUguwUDfRll37mDJ/Le8fN5COs3+R2/mOG7INJUmSpBZjoW6iB19Zzb66eq46pR/MvBOOfw/0Kt2l/SRJktS8LNRN9PsZNZxwdA9O3DQFdm+C0z+ddSRJkiS1oKK+KbHVqq+DOfewbs1y3vnGMt59Qn949mHoPwaGnp11OkmSJLUgC/WRmP4zePhr9Ae+3h6ozu//h5+4VJ4kSVIbY6E+XNtWw9R/pX74uzlr2ScYf2xfbv3IqRAV0K5D1ukkSZLUwpxDfbgeuQXq9/PMcd9gza7gHyYOh/adLNOSJEltlIX6cLz6KCz4Hzjnq/x6MVR178i5x1VlnUqSJEkZslAXat9OeOgrUDWajad8micXr+cDpw2kXaWnUJIkqS1zDnWhnvoebF0B1z/MSyt2UFefuPjEAVmnkiRJUsYcXi3EG/Pg+Vvh1I/BsWcybekmOrWvYOwxPbNOJkmSpIxZqAvRoSuMuQIu/A4A05dt4tTBvenQztMnSZLU1tkIC9FnGFz1C+jSh+179rNwzTbeMaxP1qkkSZJUAizUh2nm8s3UJ5g41EItSZIkC/Vhm75sE5UVwalDemUdRZIkSSXAQn2Ypi/dzNhjetC1owukSJIkyUJ9WPbW1vFyzRbe4XQPSZIk5VmoD8Pcmq3sq633DYmSJEn6Kwv1YZi2bBOAI9SSJEn6Kwv1YZi+dBMj+3ejT9cOWUeRJElSibBQF6iuPjFj+WZHpyVJkvR3LNQFWvzGdrbvqWXisN5ZR5EkSVIJsVAXaLrzpyVJktQIC3WBpi3bxDE9OzGod5eso0iSJKmEWKgLkFJi+tJNLpcnSZKkt7BQF2DFpl2s276XCU73kCRJ0gEs1AXYvGs/Ywf24HRHqCVJknSAdlkHKAfjBvfiz58/O+sYkiRJKkGOUEuSJElNYKGWJEmSmsBCLUmSJDWBhVqSJElqAgu1JEmS1AQWakmSJKkJLNSSJElSE1ioJUmSpCawUEuSJElNYKGWJEmSmsBCLUmSJDWBhVqSJElqAgu1JEmS1ARFLdQRcUlELI6I6oi4pZHnz4mIWRFRGxEfLGYWSZIkqRiKVqgjohK4DbgUGANcExFjDjhsBfBx4K5i5ZAkSZKKqV0RX3siUJ1SWgIQEXcDVwAL3jwgpbQs/1x9EXNIkiRJRVPMKR8DgZUNtmvy+yRJkqRWo5iFOhrZl47ohSJujIgZETFj/fr1TYwlSZIkNZ9iTvmoAQY32B4ErD6SF0op3Q7cDhAR6yNiedPjHVI/YEMLfJ/WzvPYPDyPzcPz2HSew+bheWwensem8xy+vWMLOaiYhXo6MCoihgGrgKuBjzT1RVNKVU19jUJExIyU0oSW+F6tmeexeXgem4fnsek8h83D89g8PI9N5zlsHkWb8pFSqgVuAh4FFgL3ppTmR8R3IuJygIh4R0TUAFcBP4mI+cXKI0mSJBVDMUeoSSlNBiYfsO/bDR5PJzcVRJIkSSpL3inx4G7POkAr4XlsHp7H5uF5bDrPYfPwPDYPz2PTeQ6bQaR0RAtvSJIkScIRakmSJKlJLNSNiIhLImJxRFRHxC1Z5ykXETE4Ip6MiIURMT8ivpDf3ycipkTEa/nPvbPOWuoiojIiZkfEn/PbwyLipfw5vCciOmSdsdRFRK+IuC8iFuWvyTO8Fg9fRHwx/+d5XkT8LiI6eT0eWkTcERHrImJeg32NXn+R86P875w5EXFadslLx0HO4b/n/0zPiYg/RESvBs99I38OF0fExdmkLj2NnccGz30lIlJE9Mtvey0eIQv1ASKiErgNuBQYA1wTEWOyTVU2aoEvp5ROACYBn8ufu1uAqSmlUcDU/Lbe3hfIrY7zpu8BP8ifw83ADZmkKi//BTySUhoNnELufHotHoaIGAjcDExIKY0FKsktger1eGi/BC45YN/Brr9LgVH5jxuBH7dQxlL3S956DqcAY1NKJwOvAt8AyP+uuRo4Mf81/53/fa7GzyMRMRi4EFjRYLfX4hGyUL/VRKA6pbQkpbQPuBu4IuNMZSGltCalNCv/eDu5AjOQ3Pm7M3/YncD7s0lYHiJiEHAZ8LP8dgDnA/flD/EcHkJE9ADOAX4OkFLal1LagtfikWgHdI6IdkAXYA1ej4eUUnoa2HTA7oNdf1cAv0o5LwK9IuLolklauho7hymlx/LL8gK8yN9WCrsCuDultDeltBSoJvf7vM07yLUI8APga/z9Xay9Fo+QhfqtBgIrG2zX5PfpMETEUOBU4CXgqJTSGsiVbqB/dsnKwg/J/U+uPr/dF9jS4JeI1+ShDQfWA7/IT535WUR0xWvxsKSUVgH/QW4Eaw2wFZiJ1+OROtj15++dI/MJ4OH8Y8/hYcjfD2RVSumVA57yPB4hC/VbRSP7XArlMEREN+B+4P9KKW3LOk85iYj3AutSSjMb7m7kUK/Jt9cOOA34cUrpVGAnTu84bPk5vlcAw4BjgK7k/kn4QF6PTeOf8cMUEd8kN83wt2/uauQwz2EjIqIL8E3g24093cg+z2MBLNRvVQMMbrA9CFidUZayExHtyZXp36aUHsjvXvvmPxnlP6/LKl8ZOAu4PCKWkZtudD65Eete+X9yB6/JQtQANSmll/Lb95Er2F6Lh+cCYGlKaX1KaT/wAHAmXo9H6mDXn793DkNEXAe8F/jH9Le1fz2HhRtB7i/Jr+R/1wwCZkXEADyPR8xC/VbTgVH5d7F3IPcmhwczzlQW8nN9fw4sTCn9Z4OnHgSuyz++Dvifls5WLlJK30gpDUopDSV37T2RUvpH4Engg/nDPIeHkFJ6A1gZEcfnd70bWIDX4uFaAUyKiC75P99vnkevxyNzsOvvQeDa/AoLk4Ctb04N0d+LiEuArwOXp5R2NXjqQeDqiOgYEcPIvaluWhYZS11KaW5KqX9KaWj+d00NcFr+/5tei0fIG7s0IiLeQ25UsBK4I6X0/2QcqSxExDuBZ4C5/G3+7/9Nbh71vcAQcr+gr0opNfYGCTUQEe8CvpJSem9EDCc3Yt0HmA18NKW0N8t8pS4ixpF7Y2cHYAlwPblBBK/FwxAR/wJ8mNw/r88GPkluTqXX49uIiN8B7wL6AWuB/wX8kUauv/xfVm4ltxLDLuD6lNKMLHKXkoOcw28AHYGN+cNeTCl9Jn/8N8nNq64lN+Xw4QNfsy1q7DymlH7e4Pll5Fby2eC1eOQs1JIkSVITOOVDkiRJagILtSRJktQEFmpJkiSpCSzUkiRJUhNYqCVJkqQmsFBLUomLiLqIeLnBR7Pd9TEihkbEvOZ6PUlqi9od+hBJUsZ2p5TGZR1CktQ4R6glqUxFxLKI+F5ETMt/jMzvPzYipkbEnPznIfn9R0XEHyLilfzHmfmXqoyIn0bE/Ih4LCI654+/OSIW5F/n7ox+TEkqeRZqSSp9nQ+Y8vHhBs9tSylNJHd3sx/m990K/CqldDLwW+BH+f0/Ap5KKZ0CnAbMz+8fBdyWUjoR2AJcmd9/C3Bq/nU+U6wfTpLKnXdKlKQSFxE7UkrdGtm/DDg/pbQkItoDb6SU+kbEBuDolNL+/P41KaV+EbEeGNTwNuERMRSYklIald/+OtA+pfRvEfEIsIPcLbP/mFLaUeQfVZLKkiPUklTe0kEeH+yYxuxt8LiOv72/5jLgNmA8MDMifN+NJDXCQi1J5e3DDT6/kH/8PHB1/vE/As/mH08FPgsQEZUR0eNgLxoRFcDglNKTwNeAXsBbRsklSa7yIUnloHNEvNxg+5GU0ptL53WMiJfIDZBck993M3BHRHwVWA9cn9//BeD2iLiB3Ej0Z4E1B/melcBvIqInEMAPUkpbmu0nkqRWxDnUklSm8nOoJ6SUNmSdRZLaMqd8SJIkSU3gCLUkSZLUBI5QS5IkSU1goZYkSZKawEItSZIkNYGFWpIkSWoCC7UkSZLUBBZqSZIkqQn+f+F12qV9LBdqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and validation sets\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = baseline_model_val_dict['acc']\n",
    "val_acc_values = baseline_model_val_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values)+1)\n",
    "ax.plot(epochs, acc_values, label='Training Accuracy')\n",
    "ax.plot(epochs, val_acc_values, label='Validation Accuracy')\n",
    "ax.set_title('Training v. Validation Accuracy')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:39:45.831032Z",
     "start_time": "2020-09-09T22:39:45.778036Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:45:56.862812Z",
     "start_time": "2020-09-09T22:45:56.857815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "                  ModelCheckpoint(filepath='best_model.h5', \n",
    "                                  monitor='val_loss',\n",
    "                                 save_best_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:50:12.753084Z",
     "start_time": "2020-09-09T22:49:40.552895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.9357 - acc: 0.1664 - val_loss: 1.9289 - val_acc: 0.1840\n",
      "Epoch 2/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.9209 - acc: 0.1827 - val_loss: 1.9140 - val_acc: 0.1960\n",
      "Epoch 3/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.9048 - acc: 0.2013 - val_loss: 1.8983 - val_acc: 0.2190\n",
      "Epoch 4/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.8877 - acc: 0.2264 - val_loss: 1.8824 - val_acc: 0.2380\n",
      "Epoch 5/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.8701 - acc: 0.2524 - val_loss: 1.8664 - val_acc: 0.2590\n",
      "Epoch 6/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.8514 - acc: 0.2775 - val_loss: 1.8496 - val_acc: 0.2760\n",
      "Epoch 7/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.8312 - acc: 0.3033 - val_loss: 1.8306 - val_acc: 0.2890\n",
      "Epoch 8/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.8092 - acc: 0.3236 - val_loss: 1.8093 - val_acc: 0.3120\n",
      "Epoch 9/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.7847 - acc: 0.3477 - val_loss: 1.7852 - val_acc: 0.3400\n",
      "Epoch 10/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7572 - acc: 0.3780 - val_loss: 1.7575 - val_acc: 0.3680\n",
      "Epoch 11/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.7267 - acc: 0.4143 - val_loss: 1.7273 - val_acc: 0.3930\n",
      "Epoch 12/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.6926 - acc: 0.4405 - val_loss: 1.6935 - val_acc: 0.4220\n",
      "Epoch 13/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.6556 - acc: 0.4645 - val_loss: 1.6562 - val_acc: 0.4500\n",
      "Epoch 14/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.6160 - acc: 0.4885 - val_loss: 1.6157 - val_acc: 0.4770\n",
      "Epoch 15/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.5741 - acc: 0.5081 - val_loss: 1.5737 - val_acc: 0.4910\n",
      "Epoch 16/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5304 - acc: 0.5279 - val_loss: 1.5290 - val_acc: 0.5110\n",
      "Epoch 17/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 1.4853 - acc: 0.5461 - val_loss: 1.4843 - val_acc: 0.5270\n",
      "Epoch 18/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.4391 - acc: 0.5633 - val_loss: 1.4372 - val_acc: 0.5430\n",
      "Epoch 19/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.3928 - acc: 0.5861 - val_loss: 1.3923 - val_acc: 0.5560\n",
      "Epoch 20/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3466 - acc: 0.5992 - val_loss: 1.3480 - val_acc: 0.5640\n",
      "Epoch 21/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.3012 - acc: 0.6113 - val_loss: 1.3018 - val_acc: 0.5780\n",
      "Epoch 22/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.2572 - acc: 0.6256 - val_loss: 1.2597 - val_acc: 0.5880\n",
      "Epoch 23/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.2150 - acc: 0.6381 - val_loss: 1.2189 - val_acc: 0.5990\n",
      "Epoch 24/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.1746 - acc: 0.6495 - val_loss: 1.1837 - val_acc: 0.6030\n",
      "Epoch 25/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.1365 - acc: 0.6567 - val_loss: 1.1454 - val_acc: 0.6240\n",
      "Epoch 26/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.1002 - acc: 0.6671 - val_loss: 1.1101 - val_acc: 0.6320\n",
      "Epoch 27/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.0659 - acc: 0.6756 - val_loss: 1.0790 - val_acc: 0.6430\n",
      "Epoch 28/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0340 - acc: 0.6817 - val_loss: 1.0493 - val_acc: 0.6460\n",
      "Epoch 29/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.0043 - acc: 0.6873 - val_loss: 1.0199 - val_acc: 0.6590\n",
      "Epoch 30/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.9762 - acc: 0.6941 - val_loss: 0.9954 - val_acc: 0.6610\n",
      "Epoch 31/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.9504 - acc: 0.6999 - val_loss: 0.9713 - val_acc: 0.6730\n",
      "Epoch 32/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9258 - acc: 0.7060 - val_loss: 0.9502 - val_acc: 0.6660\n",
      "Epoch 33/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9035 - acc: 0.7108 - val_loss: 0.9294 - val_acc: 0.6780\n",
      "Epoch 34/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.8823 - acc: 0.7149 - val_loss: 0.9115 - val_acc: 0.6780\n",
      "Epoch 35/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.8630 - acc: 0.7185 - val_loss: 0.8960 - val_acc: 0.6920\n",
      "Epoch 36/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8448 - acc: 0.7233 - val_loss: 0.8781 - val_acc: 0.6880\n",
      "Epoch 37/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.8275 - acc: 0.7281 - val_loss: 0.8625 - val_acc: 0.6960\n",
      "Epoch 38/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.8119 - acc: 0.7308 - val_loss: 0.8493 - val_acc: 0.6930\n",
      "Epoch 39/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7969 - acc: 0.7320 - val_loss: 0.8369 - val_acc: 0.6960\n",
      "Epoch 40/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.7828 - acc: 0.7363 - val_loss: 0.8245 - val_acc: 0.7050\n",
      "Epoch 41/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7694 - acc: 0.7397 - val_loss: 0.8143 - val_acc: 0.7030\n",
      "Epoch 42/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7569 - acc: 0.7452 - val_loss: 0.8089 - val_acc: 0.7040\n",
      "Epoch 43/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.7451 - acc: 0.7503 - val_loss: 0.7953 - val_acc: 0.7120\n",
      "Epoch 44/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.7337 - acc: 0.7536 - val_loss: 0.7865 - val_acc: 0.7150\n",
      "Epoch 45/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7230 - acc: 0.7551 - val_loss: 0.7785 - val_acc: 0.7160\n",
      "Epoch 46/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7133 - acc: 0.7572 - val_loss: 0.7722 - val_acc: 0.7110\n",
      "Epoch 47/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7035 - acc: 0.7588 - val_loss: 0.7616 - val_acc: 0.7240\n",
      "Epoch 48/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6941 - acc: 0.7627 - val_loss: 0.7578 - val_acc: 0.7200\n",
      "Epoch 49/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6853 - acc: 0.7655 - val_loss: 0.7497 - val_acc: 0.7200\n",
      "Epoch 50/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.6772 - acc: 0.7657 - val_loss: 0.7436 - val_acc: 0.7220\n",
      "Epoch 51/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.6690 - acc: 0.7684 - val_loss: 0.7420 - val_acc: 0.7260\n",
      "Epoch 52/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6612 - acc: 0.7729 - val_loss: 0.7370 - val_acc: 0.7290\n",
      "Epoch 53/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6540 - acc: 0.7749 - val_loss: 0.7300 - val_acc: 0.7240\n",
      "Epoch 54/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6467 - acc: 0.7749 - val_loss: 0.7230 - val_acc: 0.7300\n",
      "Epoch 55/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.6392 - acc: 0.7780 - val_loss: 0.7235 - val_acc: 0.7210\n",
      "Epoch 56/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6328 - acc: 0.7791 - val_loss: 0.7155 - val_acc: 0.7280\n",
      "Epoch 57/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.6265 - acc: 0.7821 - val_loss: 0.7104 - val_acc: 0.7320\n",
      "Epoch 58/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6199 - acc: 0.7837 - val_loss: 0.7077 - val_acc: 0.7370\n",
      "Epoch 59/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.6140 - acc: 0.7865 - val_loss: 0.7062 - val_acc: 0.7370\n",
      "Epoch 60/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6081 - acc: 0.7869 - val_loss: 0.7023 - val_acc: 0.7340\n",
      "Epoch 61/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.6021 - acc: 0.7903 - val_loss: 0.6967 - val_acc: 0.7370\n",
      "Epoch 62/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5969 - acc: 0.7917 - val_loss: 0.6954 - val_acc: 0.7360\n",
      "Epoch 63/150\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.5914 - acc: 0.7953 - val_loss: 0.6907 - val_acc: 0.7400\n",
      "Epoch 64/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.5859 - acc: 0.7948 - val_loss: 0.6903 - val_acc: 0.7380\n",
      "Epoch 65/150\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5810 - acc: 0.7960 - val_loss: 0.6876 - val_acc: 0.7430\n",
      "Epoch 66/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5759 - acc: 0.8003 - val_loss: 0.6833 - val_acc: 0.7400\n",
      "Epoch 67/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5710 - acc: 0.8019 - val_loss: 0.6804 - val_acc: 0.7440\n",
      "Epoch 68/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5661 - acc: 0.8040 - val_loss: 0.6781 - val_acc: 0.7420\n",
      "Epoch 69/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.5615 - acc: 0.8044 - val_loss: 0.6798 - val_acc: 0.7410\n",
      "Epoch 70/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.5567 - acc: 0.8053 - val_loss: 0.6763 - val_acc: 0.7380\n",
      "Epoch 71/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5523 - acc: 0.8055 - val_loss: 0.6751 - val_acc: 0.7410\n",
      "Epoch 72/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5478 - acc: 0.8085 - val_loss: 0.6745 - val_acc: 0.7440\n",
      "Epoch 73/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5435 - acc: 0.8091 - val_loss: 0.6744 - val_acc: 0.7380\n",
      "Epoch 74/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.5389 - acc: 0.8112 - val_loss: 0.6684 - val_acc: 0.7420\n",
      "Epoch 75/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5349 - acc: 0.8123 - val_loss: 0.6691 - val_acc: 0.7470\n",
      "Epoch 76/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5308 - acc: 0.8148 - val_loss: 0.6654 - val_acc: 0.7430\n",
      "Epoch 77/150\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5272 - acc: 0.8175 - val_loss: 0.6625 - val_acc: 0.7510\n",
      "Epoch 78/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.5224 - acc: 0.8184 - val_loss: 0.6615 - val_acc: 0.7460\n",
      "Epoch 79/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5184 - acc: 0.8197 - val_loss: 0.6597 - val_acc: 0.7410\n",
      "Epoch 80/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5145 - acc: 0.8200 - val_loss: 0.6639 - val_acc: 0.7460\n",
      "Epoch 81/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.5105 - acc: 0.8232 - val_loss: 0.6650 - val_acc: 0.7460\n",
      "Epoch 82/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.5076 - acc: 0.8252 - val_loss: 0.6557 - val_acc: 0.7470\n",
      "Epoch 83/150\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.5034 - acc: 0.8253 - val_loss: 0.6533 - val_acc: 0.7480\n",
      "Epoch 84/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4999 - acc: 0.8260 - val_loss: 0.6534 - val_acc: 0.7460\n",
      "Epoch 85/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4958 - acc: 0.8284 - val_loss: 0.6551 - val_acc: 0.7460\n",
      "Epoch 86/150\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4920 - acc: 0.8299 - val_loss: 0.6545 - val_acc: 0.7440\n",
      "Epoch 87/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4886 - acc: 0.8297 - val_loss: 0.6509 - val_acc: 0.7470\n",
      "Epoch 88/150\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4851 - acc: 0.8328 - val_loss: 0.6503 - val_acc: 0.7480\n",
      "Epoch 89/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4815 - acc: 0.8345 - val_loss: 0.6494 - val_acc: 0.7450\n",
      "Epoch 90/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4782 - acc: 0.8381 - val_loss: 0.6520 - val_acc: 0.7460\n",
      "Epoch 91/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.4751 - acc: 0.8377 - val_loss: 0.6501 - val_acc: 0.7490\n",
      "Epoch 92/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4712 - acc: 0.8392 - val_loss: 0.6485 - val_acc: 0.7500\n",
      "Epoch 93/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4678 - acc: 0.8393 - val_loss: 0.6503 - val_acc: 0.7480\n",
      "Epoch 94/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4647 - acc: 0.8431 - val_loss: 0.6479 - val_acc: 0.7470\n",
      "Epoch 95/150\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4615 - acc: 0.8449 - val_loss: 0.6495 - val_acc: 0.7470\n",
      "Epoch 96/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4580 - acc: 0.8452 - val_loss: 0.6457 - val_acc: 0.7450\n",
      "Epoch 97/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4548 - acc: 0.8463 - val_loss: 0.6502 - val_acc: 0.7480\n",
      "Epoch 98/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4516 - acc: 0.8467 - val_loss: 0.6504 - val_acc: 0.7520\n",
      "Epoch 99/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4486 - acc: 0.8485 - val_loss: 0.6439 - val_acc: 0.7450\n",
      "Epoch 100/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4453 - acc: 0.8505 - val_loss: 0.6418 - val_acc: 0.7490\n",
      "Epoch 101/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4423 - acc: 0.8527 - val_loss: 0.6446 - val_acc: 0.7490\n",
      "Epoch 102/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4397 - acc: 0.8525 - val_loss: 0.6456 - val_acc: 0.7470\n",
      "Epoch 103/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4362 - acc: 0.8537 - val_loss: 0.6470 - val_acc: 0.7430\n",
      "Epoch 104/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.4333 - acc: 0.8540 - val_loss: 0.6457 - val_acc: 0.7500\n",
      "Epoch 105/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4302 - acc: 0.8573 - val_loss: 0.6436 - val_acc: 0.7480\n",
      "Epoch 106/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4275 - acc: 0.8559 - val_loss: 0.6432 - val_acc: 0.7450\n",
      "Epoch 107/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4241 - acc: 0.8584 - val_loss: 0.6432 - val_acc: 0.7510\n",
      "Epoch 108/150\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.4213 - acc: 0.8587 - val_loss: 0.6475 - val_acc: 0.7490\n",
      "Epoch 109/150\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.4185 - acc: 0.8592 - val_loss: 0.6456 - val_acc: 0.7430\n",
      "Epoch 110/150\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.4154 - acc: 0.8629 - val_loss: 0.6434 - val_acc: 0.7480\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(X_train_tokens, y_train_lb, epochs=150, \n",
    "                      callbacks=early_stopping, batch_size=256, \n",
    "                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:50:43.499525Z",
     "start_time": "2020-09-09T22:50:43.095804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T22:52:38.963541Z",
     "start_time": "2020-09-09T22:52:38.664711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 32us/step\n",
      "Training Loss: 0.443 \n",
      "Training Accuracy: 0.85\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 36us/step\n",
      "Test Loss: 0.614 \n",
      "Test Accuracy: 0.762\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regularizers\n",
    "\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "\n",
    "\n",
    "# Add another hidden layer\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['acc'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_acc']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "\n",
    "\n",
    "# Add a hidden layer\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "\n",
    "\n",
    "# Add the first hidden layer\n",
    "\n",
    "\n",
    "# Implement dropout to the first hidden layer \n",
    "\n",
    "\n",
    "# Add the second hidden layer\n",
    "\n",
    "\n",
    "# Implement dropout to the second hidden layer \n",
    "\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_train = model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
